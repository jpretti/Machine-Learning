{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDo6Mz1MoJxR",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "Turn in the assignment via Canvas.\n",
        "\n",
        "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel→→Restart) and then run all cells (in the menubar, select Cell→→Run All).\n",
        "\n",
        "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOfazHDtoJxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NAME = \"James Pretti\"\n",
        "STUDENT_ID = \"1676114\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPWO4eaSZtaX",
        "colab_type": "text"
      },
      "source": [
        "# 1) Binary Classification\n",
        "## i) Logistic Regression\n",
        "In this task, we will run logistic regression using scikit learn. But first the dataset needs to be created. Call this data set the Gaussian Quantile Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxTRTcKn46Xk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5b959223-c314-4c4a-c4de-6877c1f11ea0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import make_gaussian_quantiles\n",
        "np.random.seed(111)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJuAZKiBO2CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct dataset\n",
        "X, y = make_gaussian_quantiles(cov=4.,\n",
        "                                 n_samples=500, n_features=1,\n",
        "                                 n_classes=2, random_state=1)\n",
        "# Making X1 values, reshape y1, and creating random noise for x1 values\n",
        "X = X-3.0  \n",
        "noise = np.random.normal(loc=0.0, scale=0.4, size=len(X)).reshape(-1,1)\n",
        "y = y.reshape(-1,1)\n",
        "X = np.sum([X,noise],axis=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfmus1-hbQWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86a47a88-1b44-4760-c24d-99eeb1ec3d80"
      },
      "source": [
        "# The dataset\n",
        "print(np.concatenate((X,y), axis=1, out=None))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.42338811e+00  0.00000000e+00]\n",
            " [ 1.53512714e+00  1.00000000e+00]\n",
            " [-2.97599422e+00  0.00000000e+00]\n",
            " [ 4.78916909e-01  1.00000000e+00]\n",
            " [-1.60960529e+00  1.00000000e+00]\n",
            " [-3.55691511e+00  0.00000000e+00]\n",
            " [-3.86154330e+00  0.00000000e+00]\n",
            " [-3.07094921e+00  0.00000000e+00]\n",
            " [ 2.76750500e+00  1.00000000e+00]\n",
            " [-2.41581646e+00  0.00000000e+00]\n",
            " [-4.62707507e+00  1.00000000e+00]\n",
            " [-4.74476399e+00  1.00000000e+00]\n",
            " [-3.00505940e+00  0.00000000e+00]\n",
            " [ 5.43380441e-01  1.00000000e+00]\n",
            " [-5.55712418e+00  1.00000000e+00]\n",
            " [-1.41449115e+00  1.00000000e+00]\n",
            " [-2.27826391e+00  0.00000000e+00]\n",
            " [-1.94740223e+00  0.00000000e+00]\n",
            " [-2.46007512e+00  0.00000000e+00]\n",
            " [-3.76786255e+00  0.00000000e+00]\n",
            " [-7.59123156e-01  1.00000000e+00]\n",
            " [-3.92296941e+00  0.00000000e+00]\n",
            " [-1.40830029e+00  1.00000000e+00]\n",
            " [-3.51714486e+00  0.00000000e+00]\n",
            " [-6.91583977e-01  1.00000000e+00]\n",
            " [-3.25406548e+00  0.00000000e+00]\n",
            " [-4.70192512e+00  0.00000000e+00]\n",
            " [-2.88430556e+00  0.00000000e+00]\n",
            " [-3.82868876e+00  0.00000000e+00]\n",
            " [-3.60400991e-01  1.00000000e+00]\n",
            " [-6.66456109e+00  1.00000000e+00]\n",
            " [-4.78099987e+00  1.00000000e+00]\n",
            " [-1.78596116e+00  1.00000000e+00]\n",
            " [-1.41492005e-01  1.00000000e+00]\n",
            " [-6.37809602e-01  1.00000000e+00]\n",
            " [-2.48720638e+00  0.00000000e+00]\n",
            " [ 1.08349034e+00  1.00000000e+00]\n",
            " [-2.90674484e+00  0.00000000e+00]\n",
            " [-2.37943799e+00  0.00000000e+00]\n",
            " [-3.04426113e+00  0.00000000e+00]\n",
            " [-1.75114584e+00  1.00000000e+00]\n",
            " [-1.31106928e+00  1.00000000e+00]\n",
            " [-3.59129260e+00  0.00000000e+00]\n",
            " [-3.36051923e+00  0.00000000e+00]\n",
            " [-3.97867615e+00  0.00000000e+00]\n",
            " [-5.00806191e+00  1.00000000e+00]\n",
            " [-2.67797355e+00  0.00000000e+00]\n",
            " [-1.17774258e+00  1.00000000e+00]\n",
            " [-3.17578094e+00  0.00000000e+00]\n",
            " [-8.34086510e+00  1.00000000e+00]\n",
            " [-4.69215016e+00  1.00000000e+00]\n",
            " [-4.72072708e+00  1.00000000e+00]\n",
            " [-2.79082805e+00  0.00000000e+00]\n",
            " [-3.67630551e+00  0.00000000e+00]\n",
            " [-3.71451248e+00  0.00000000e+00]\n",
            " [-3.80044531e+00  0.00000000e+00]\n",
            " [-3.22549530e+00  0.00000000e+00]\n",
            " [-3.89688775e+00  1.00000000e+00]\n",
            " [-2.92101492e+00  0.00000000e+00]\n",
            " [-2.60597718e+00  0.00000000e+00]\n",
            " [-2.20079525e+00  0.00000000e+00]\n",
            " [-2.62121238e+00  0.00000000e+00]\n",
            " [-5.38769320e+00  1.00000000e+00]\n",
            " [-3.08269940e+00  0.00000000e+00]\n",
            " [-3.16197726e+00  0.00000000e+00]\n",
            " [ 7.05889606e-01  1.00000000e+00]\n",
            " [-7.33526992e+00  1.00000000e+00]\n",
            " [-5.54998301e+00  1.00000000e+00]\n",
            " [-2.32227522e-01  1.00000000e+00]\n",
            " [-1.22745100e+00  1.00000000e+00]\n",
            " [-4.99570882e+00  1.00000000e+00]\n",
            " [-4.29842738e+00  1.00000000e+00]\n",
            " [-6.83059970e+00  1.00000000e+00]\n",
            " [-7.67863833e-01  1.00000000e+00]\n",
            " [-3.41406793e+00  0.00000000e+00]\n",
            " [-3.73846357e+00  0.00000000e+00]\n",
            " [-1.83206160e+00  0.00000000e+00]\n",
            " [-5.07154524e+00  1.00000000e+00]\n",
            " [-2.43974314e+00  0.00000000e+00]\n",
            " [-2.49269014e+00  0.00000000e+00]\n",
            " [-3.70631635e+00  0.00000000e+00]\n",
            " [-2.15399972e+00  0.00000000e+00]\n",
            " [-5.04894497e+00  1.00000000e+00]\n",
            " [-8.23848102e-01  1.00000000e+00]\n",
            " [-4.31693341e+00  1.00000000e+00]\n",
            " [ 8.60893285e-01  1.00000000e+00]\n",
            " [-3.43153949e+00  0.00000000e+00]\n",
            " [-5.55562089e+00  1.00000000e+00]\n",
            " [-1.14591263e+00  1.00000000e+00]\n",
            " [-6.09732604e+00  1.00000000e+00]\n",
            " [-4.90396727e+00  1.00000000e+00]\n",
            " [-3.89485620e+00  1.00000000e+00]\n",
            " [-5.51515317e+00  1.00000000e+00]\n",
            " [ 7.66076940e-01  1.00000000e+00]\n",
            " [-8.39082007e-02  1.00000000e+00]\n",
            " [-7.15328437e-01  1.00000000e+00]\n",
            " [-4.08272527e+00  0.00000000e+00]\n",
            " [-2.17451276e+00  0.00000000e+00]\n",
            " [-4.86837635e+00  0.00000000e+00]\n",
            " [-1.53786733e+00  1.00000000e+00]\n",
            " [-3.64621959e+00  0.00000000e+00]\n",
            " [ 1.11816292e+00  1.00000000e+00]\n",
            " [-4.38975676e+00  1.00000000e+00]\n",
            " [-2.02483538e+00  1.00000000e+00]\n",
            " [-4.91624155e+00  1.00000000e+00]\n",
            " [-3.20540604e+00  0.00000000e+00]\n",
            " [-6.50767723e+00  1.00000000e+00]\n",
            " [ 5.66094603e-01  1.00000000e+00]\n",
            " [-5.81549034e+00  1.00000000e+00]\n",
            " [-2.76990269e+00  0.00000000e+00]\n",
            " [-1.50617117e+00  0.00000000e+00]\n",
            " [-4.84958371e+00  1.00000000e+00]\n",
            " [-1.73696722e+00  0.00000000e+00]\n",
            " [-3.17506998e+00  0.00000000e+00]\n",
            " [-1.12256336e+00  1.00000000e+00]\n",
            " [-6.82408037e+00  1.00000000e+00]\n",
            " [-4.60467195e+00  1.00000000e+00]\n",
            " [ 1.76040317e+00  1.00000000e+00]\n",
            " [-2.29246561e+00  0.00000000e+00]\n",
            " [-5.49745030e-01  1.00000000e+00]\n",
            " [-3.16631699e+00  0.00000000e+00]\n",
            " [-2.52677491e+00  0.00000000e+00]\n",
            " [-2.24129038e+00  0.00000000e+00]\n",
            " [-5.61034517e+00  1.00000000e+00]\n",
            " [-1.00895521e+00  1.00000000e+00]\n",
            " [-9.14911816e-01  1.00000000e+00]\n",
            " [-5.32327875e-01  1.00000000e+00]\n",
            " [ 9.74874549e-01  1.00000000e+00]\n",
            " [-4.10910791e+00  0.00000000e+00]\n",
            " [-2.23104553e+00  0.00000000e+00]\n",
            " [-5.54449452e+00  1.00000000e+00]\n",
            " [-3.36713342e+00  0.00000000e+00]\n",
            " [-9.44993219e-01  1.00000000e+00]\n",
            " [-5.63019792e+00  1.00000000e+00]\n",
            " [-1.86024671e+00  0.00000000e+00]\n",
            " [-2.65977759e+00  0.00000000e+00]\n",
            " [-1.17829749e+00  1.00000000e+00]\n",
            " [-4.81607587e+00  1.00000000e+00]\n",
            " [-3.96265323e+00  0.00000000e+00]\n",
            " [ 1.41353601e-01  1.00000000e+00]\n",
            " [-4.66998839e+00  0.00000000e+00]\n",
            " [-2.60008341e+00  0.00000000e+00]\n",
            " [-7.82737723e-03  1.00000000e+00]\n",
            " [-4.57594332e+00  1.00000000e+00]\n",
            " [-1.87429665e+00  0.00000000e+00]\n",
            " [-1.57851247e+00  0.00000000e+00]\n",
            " [-3.77873222e+00  0.00000000e+00]\n",
            " [-4.46535774e-01  1.00000000e+00]\n",
            " [-4.51510509e+00  1.00000000e+00]\n",
            " [-2.88383019e+00  0.00000000e+00]\n",
            " [-4.59225669e+00  0.00000000e+00]\n",
            " [-2.48852287e+00  0.00000000e+00]\n",
            " [-1.57589087e+00  1.00000000e+00]\n",
            " [-3.68492738e+00  0.00000000e+00]\n",
            " [-2.67199213e+00  0.00000000e+00]\n",
            " [-4.56004468e+00  1.00000000e+00]\n",
            " [-1.77073022e+00  1.00000000e+00]\n",
            " [-7.75056411e-01  1.00000000e+00]\n",
            " [-4.29463631e+00  1.00000000e+00]\n",
            " [-2.25683023e+00  0.00000000e+00]\n",
            " [-2.02736724e+00  0.00000000e+00]\n",
            " [-2.08596832e+00  0.00000000e+00]\n",
            " [-2.12056247e+00  0.00000000e+00]\n",
            " [-1.49484221e+00  1.00000000e+00]\n",
            " [-3.55524144e+00  0.00000000e+00]\n",
            " [-3.93125874e+00  0.00000000e+00]\n",
            " [-5.02481406e+00  0.00000000e+00]\n",
            " [-6.83217630e+00  1.00000000e+00]\n",
            " [-2.77869949e+00  0.00000000e+00]\n",
            " [-6.40746336e+00  1.00000000e+00]\n",
            " [-3.09735811e+00  0.00000000e+00]\n",
            " [-4.03537732e+00  0.00000000e+00]\n",
            " [-3.35051372e+00  0.00000000e+00]\n",
            " [-2.94358007e+00  0.00000000e+00]\n",
            " [-2.82369950e+00  0.00000000e+00]\n",
            " [-1.40338153e+00  1.00000000e+00]\n",
            " [-5.67597415e+00  1.00000000e+00]\n",
            " [-4.02281243e+00  0.00000000e+00]\n",
            " [-1.31766979e+00  1.00000000e+00]\n",
            " [-6.34645402e+00  1.00000000e+00]\n",
            " [-3.00555118e+00  0.00000000e+00]\n",
            " [ 3.88017990e-01  1.00000000e+00]\n",
            " [ 8.17664950e-01  1.00000000e+00]\n",
            " [-2.05139307e+00  0.00000000e+00]\n",
            " [-5.39761484e+00  1.00000000e+00]\n",
            " [-2.99462264e+00  0.00000000e+00]\n",
            " [-2.51530713e+00  0.00000000e+00]\n",
            " [-4.32320344e+00  1.00000000e+00]\n",
            " [-3.33086808e+00  0.00000000e+00]\n",
            " [ 2.05091625e+00  1.00000000e+00]\n",
            " [-8.08548890e-01  1.00000000e+00]\n",
            " [-4.85701732e+00  1.00000000e+00]\n",
            " [-3.49161823e+00  0.00000000e+00]\n",
            " [-5.21874710e+00  1.00000000e+00]\n",
            " [ 7.49587140e-01  1.00000000e+00]\n",
            " [-3.62891547e+00  0.00000000e+00]\n",
            " [-3.49148381e+00  0.00000000e+00]\n",
            " [-3.23036499e-01  1.00000000e+00]\n",
            " [-5.54629072e+00  1.00000000e+00]\n",
            " [-6.11178068e+00  1.00000000e+00]\n",
            " [-7.16551088e+00  1.00000000e+00]\n",
            " [-4.68076582e+00  0.00000000e+00]\n",
            " [-6.21327680e+00  1.00000000e+00]\n",
            " [-3.67441644e+00  0.00000000e+00]\n",
            " [-4.37034621e+00  1.00000000e+00]\n",
            " [-1.54414654e+00  1.00000000e+00]\n",
            " [-3.89898760e+00  0.00000000e+00]\n",
            " [-4.73480724e+00  0.00000000e+00]\n",
            " [-7.10537571e+00  1.00000000e+00]\n",
            " [-3.54751713e+00  0.00000000e+00]\n",
            " [-3.61837361e+00  0.00000000e+00]\n",
            " [-4.15716940e+00  0.00000000e+00]\n",
            " [-1.97727695e+00  0.00000000e+00]\n",
            " [-2.13475092e+00  0.00000000e+00]\n",
            " [ 2.18302059e+00  1.00000000e+00]\n",
            " [-3.27063884e+00  0.00000000e+00]\n",
            " [-2.09641976e+00  0.00000000e+00]\n",
            " [-4.09798455e+00  0.00000000e+00]\n",
            " [-2.70694167e+00  0.00000000e+00]\n",
            " [-3.72839642e+00  0.00000000e+00]\n",
            " [-2.16391476e+00  0.00000000e+00]\n",
            " [-2.33823207e+00  0.00000000e+00]\n",
            " [-3.49096891e+00  0.00000000e+00]\n",
            " [-6.83972239e-01  1.00000000e+00]\n",
            " [-3.10283208e+00  0.00000000e+00]\n",
            " [-3.77574665e+00  0.00000000e+00]\n",
            " [-1.42751551e+00  1.00000000e+00]\n",
            " [-7.57285331e+00  1.00000000e+00]\n",
            " [-4.21072535e+00  1.00000000e+00]\n",
            " [-5.60477208e+00  1.00000000e+00]\n",
            " [-3.19116825e+00  0.00000000e+00]\n",
            " [ 7.83671803e-01  1.00000000e+00]\n",
            " [-2.77988608e+00  0.00000000e+00]\n",
            " [-4.37628989e+00  0.00000000e+00]\n",
            " [-2.91415951e+00  0.00000000e+00]\n",
            " [-4.48232434e+00  1.00000000e+00]\n",
            " [-4.91838128e+00  0.00000000e+00]\n",
            " [-3.43826595e+00  0.00000000e+00]\n",
            " [-4.42897402e-01  1.00000000e+00]\n",
            " [-1.24702108e+00  0.00000000e+00]\n",
            " [-4.81384002e+00  1.00000000e+00]\n",
            " [-1.37991743e+00  1.00000000e+00]\n",
            " [-5.54971318e+00  1.00000000e+00]\n",
            " [-3.47423561e+00  0.00000000e+00]\n",
            " [-3.50984906e+00  0.00000000e+00]\n",
            " [-2.42111994e+00  0.00000000e+00]\n",
            " [-5.49881478e-01  1.00000000e+00]\n",
            " [-5.33360736e-01  1.00000000e+00]\n",
            " [-2.62988876e+00  0.00000000e+00]\n",
            " [-4.14801589e+00  0.00000000e+00]\n",
            " [-4.25368730e+00  0.00000000e+00]\n",
            " [-1.11135334e+00  1.00000000e+00]\n",
            " [-3.01485390e+00  0.00000000e+00]\n",
            " [-3.79490766e+00  0.00000000e+00]\n",
            " [-8.46022210e-01  1.00000000e+00]\n",
            " [-4.70937522e-01  1.00000000e+00]\n",
            " [ 3.06204794e-01  1.00000000e+00]\n",
            " [-3.58021815e+00  0.00000000e+00]\n",
            " [-2.12824165e+00  0.00000000e+00]\n",
            " [-3.89167352e+00  1.00000000e+00]\n",
            " [-3.35304615e+00  0.00000000e+00]\n",
            " [-1.19028233e+00  1.00000000e+00]\n",
            " [-7.93705994e-01  1.00000000e+00]\n",
            " [-3.25526661e+00  0.00000000e+00]\n",
            " [-3.70408218e+00  0.00000000e+00]\n",
            " [-2.74001420e+00  0.00000000e+00]\n",
            " [-2.62454608e+00  0.00000000e+00]\n",
            " [-1.81200760e+00  0.00000000e+00]\n",
            " [-5.79411648e+00  1.00000000e+00]\n",
            " [-2.77665636e+00  0.00000000e+00]\n",
            " [-1.85466228e+00  0.00000000e+00]\n",
            " [-4.30173544e+00  1.00000000e+00]\n",
            " [-5.79472946e+00  1.00000000e+00]\n",
            " [-1.76779194e+00  0.00000000e+00]\n",
            " [-3.71100160e+00  0.00000000e+00]\n",
            " [-6.79068523e+00  1.00000000e+00]\n",
            " [-3.68726664e+00  0.00000000e+00]\n",
            " [-1.32649745e+00  1.00000000e+00]\n",
            " [-3.20236669e+00  0.00000000e+00]\n",
            " [-3.78894330e+00  0.00000000e+00]\n",
            " [-4.50323902e+00  1.00000000e+00]\n",
            " [ 7.97527323e-01  1.00000000e+00]\n",
            " [-4.95132307e+00  1.00000000e+00]\n",
            " [-1.99876834e+00  0.00000000e+00]\n",
            " [ 9.84705957e-01  1.00000000e+00]\n",
            " [-5.38284428e+00  1.00000000e+00]\n",
            " [-4.65375004e+00  0.00000000e+00]\n",
            " [ 1.15715908e+00  1.00000000e+00]\n",
            " [-6.89770012e+00  1.00000000e+00]\n",
            " [ 1.54430028e+00  1.00000000e+00]\n",
            " [-5.27875548e-01  1.00000000e+00]\n",
            " [-3.82428786e+00  0.00000000e+00]\n",
            " [-4.99452635e+00  1.00000000e+00]\n",
            " [-3.40194554e+00  0.00000000e+00]\n",
            " [-3.85693950e+00  0.00000000e+00]\n",
            " [-1.91442588e+00  0.00000000e+00]\n",
            " [-1.87752184e+00  1.00000000e+00]\n",
            " [-6.65578183e-01  1.00000000e+00]\n",
            " [-2.35853646e+00  0.00000000e+00]\n",
            " [-1.43176463e+00  1.00000000e+00]\n",
            " [-1.63336726e+00  1.00000000e+00]\n",
            " [-2.10400808e+00  0.00000000e+00]\n",
            " [-3.82029165e+00  1.00000000e+00]\n",
            " [-3.96112712e+00  0.00000000e+00]\n",
            " [-2.47990816e+00  0.00000000e+00]\n",
            " [-2.57227075e+00  0.00000000e+00]\n",
            " [-3.82485866e+00  0.00000000e+00]\n",
            " [-7.15925381e-01  1.00000000e+00]\n",
            " [-3.61572938e+00  0.00000000e+00]\n",
            " [ 1.03994036e+00  1.00000000e+00]\n",
            " [-1.38957236e+00  1.00000000e+00]\n",
            " [-2.22510907e+00  0.00000000e+00]\n",
            " [-3.19410607e+00  0.00000000e+00]\n",
            " [-6.88294402e+00  1.00000000e+00]\n",
            " [-3.08065099e+00  0.00000000e+00]\n",
            " [-1.07449205e+00  1.00000000e+00]\n",
            " [-3.82605761e+00  0.00000000e+00]\n",
            " [-4.82976994e+00  1.00000000e+00]\n",
            " [-2.59321678e+00  0.00000000e+00]\n",
            " [-4.90055723e-01  1.00000000e+00]\n",
            " [-1.41768396e+00  0.00000000e+00]\n",
            " [-3.81399837e+00  0.00000000e+00]\n",
            " [-1.56218158e+00  1.00000000e+00]\n",
            " [-4.33389840e+00  1.00000000e+00]\n",
            " [-3.80984777e+00  0.00000000e+00]\n",
            " [-2.21464686e+00  0.00000000e+00]\n",
            " [-5.47313925e+00  1.00000000e+00]\n",
            " [-7.25402106e+00  1.00000000e+00]\n",
            " [-2.66127925e+00  0.00000000e+00]\n",
            " [-1.45022822e+00  1.00000000e+00]\n",
            " [-3.02588179e+00  0.00000000e+00]\n",
            " [-4.12172069e+00  0.00000000e+00]\n",
            " [-3.46118884e-01  1.00000000e+00]\n",
            " [-4.50985308e+00  0.00000000e+00]\n",
            " [-1.04345906e+00  1.00000000e+00]\n",
            " [-4.73194868e+00  1.00000000e+00]\n",
            " [-4.41371098e+00  1.00000000e+00]\n",
            " [-1.09122855e+00  1.00000000e+00]\n",
            " [-1.43939418e+00  1.00000000e+00]\n",
            " [-2.52012070e+00  0.00000000e+00]\n",
            " [-6.03870154e-01  1.00000000e+00]\n",
            " [-3.13379522e+00  0.00000000e+00]\n",
            " [-2.73846845e+00  0.00000000e+00]\n",
            " [-4.45832436e+00  0.00000000e+00]\n",
            " [-4.22424477e+00  0.00000000e+00]\n",
            " [-8.28903907e-01  1.00000000e+00]\n",
            " [-4.01518170e+00  0.00000000e+00]\n",
            " [-2.69923537e+00  0.00000000e+00]\n",
            " [-7.85466253e+00  1.00000000e+00]\n",
            " [-3.86245134e-01  1.00000000e+00]\n",
            " [-5.57256526e+00  1.00000000e+00]\n",
            " [-2.25911688e+00  0.00000000e+00]\n",
            " [ 5.18062361e-03  1.00000000e+00]\n",
            " [-2.35288413e+00  0.00000000e+00]\n",
            " [-6.16633120e+00  1.00000000e+00]\n",
            " [-3.72700376e+00  0.00000000e+00]\n",
            " [-5.87156926e+00  1.00000000e+00]\n",
            " [-2.28665563e+00  0.00000000e+00]\n",
            " [-6.43879035e+00  1.00000000e+00]\n",
            " [-1.86248480e+00  0.00000000e+00]\n",
            " [-3.90983881e+00  0.00000000e+00]\n",
            " [-1.60017272e+00  1.00000000e+00]\n",
            " [-4.08139780e+00  0.00000000e+00]\n",
            " [-6.52470261e+00  1.00000000e+00]\n",
            " [-4.35450078e+00  1.00000000e+00]\n",
            " [-5.05486389e+00  0.00000000e+00]\n",
            " [-1.89212909e+00  0.00000000e+00]\n",
            " [-6.02077878e+00  1.00000000e+00]\n",
            " [-2.33537719e+00  0.00000000e+00]\n",
            " [-1.94452141e+00  0.00000000e+00]\n",
            " [-4.50133901e+00  0.00000000e+00]\n",
            " [-4.28788164e+00  0.00000000e+00]\n",
            " [-1.22453784e+00  1.00000000e+00]\n",
            " [-1.83340272e+00  1.00000000e+00]\n",
            " [-1.46411036e+00  1.00000000e+00]\n",
            " [-3.86526574e+00  0.00000000e+00]\n",
            " [-5.30004119e+00  1.00000000e+00]\n",
            " [-6.21457188e-01  1.00000000e+00]\n",
            " [-4.84130434e+00  1.00000000e+00]\n",
            " [-2.37174327e+00  0.00000000e+00]\n",
            " [-4.60017004e+00  1.00000000e+00]\n",
            " [-4.50726295e-01  1.00000000e+00]\n",
            " [-1.95587790e+00  0.00000000e+00]\n",
            " [-3.29067218e+00  0.00000000e+00]\n",
            " [-2.96619510e+00  0.00000000e+00]\n",
            " [-3.60811513e+00  0.00000000e+00]\n",
            " [-3.23319805e+00  0.00000000e+00]\n",
            " [-2.70025538e+00  0.00000000e+00]\n",
            " [-3.98986854e+00  1.00000000e+00]\n",
            " [-8.42377486e+00  1.00000000e+00]\n",
            " [-2.51981993e+00  0.00000000e+00]\n",
            " [-4.68822875e+00  1.00000000e+00]\n",
            " [-1.93294422e-01  1.00000000e+00]\n",
            " [-2.65557721e+00  0.00000000e+00]\n",
            " [-1.69600227e+00  0.00000000e+00]\n",
            " [-5.72116396e+00  1.00000000e+00]\n",
            " [-2.94514108e+00  0.00000000e+00]\n",
            " [-4.81193902e+00  1.00000000e+00]\n",
            " [-1.63161265e+00  0.00000000e+00]\n",
            " [-2.12935731e+00  0.00000000e+00]\n",
            " [-9.15635679e-01  1.00000000e+00]\n",
            " [-1.78632323e+00  0.00000000e+00]\n",
            " [-4.18559760e+00  0.00000000e+00]\n",
            " [-3.76671865e+00  0.00000000e+00]\n",
            " [-2.22109045e+00  0.00000000e+00]\n",
            " [-8.97135100e+00  1.00000000e+00]\n",
            " [-5.67832419e+00  1.00000000e+00]\n",
            " [-2.12397740e+00  0.00000000e+00]\n",
            " [-5.29505377e+00  1.00000000e+00]\n",
            " [-1.09014623e+00  1.00000000e+00]\n",
            " [-2.89454528e+00  0.00000000e+00]\n",
            " [-5.60222978e+00  1.00000000e+00]\n",
            " [-4.53949037e+00  1.00000000e+00]\n",
            " [-6.15898685e-01  1.00000000e+00]\n",
            " [-1.33915308e+00  0.00000000e+00]\n",
            " [-3.75093253e+00  0.00000000e+00]\n",
            " [-3.12616261e+00  0.00000000e+00]\n",
            " [-6.93627522e+00  1.00000000e+00]\n",
            " [-1.91116524e+00  0.00000000e+00]\n",
            " [-4.96533199e+00  1.00000000e+00]\n",
            " [-3.35742538e+00  0.00000000e+00]\n",
            " [ 3.64066494e-01  1.00000000e+00]\n",
            " [-9.59021871e-01  1.00000000e+00]\n",
            " [-7.45821837e+00  1.00000000e+00]\n",
            " [-7.34198126e+00  1.00000000e+00]\n",
            " [-3.12079781e+00  0.00000000e+00]\n",
            " [-3.43000133e+00  0.00000000e+00]\n",
            " [-5.67009506e+00  1.00000000e+00]\n",
            " [ 2.29280430e-02  1.00000000e+00]\n",
            " [-4.24237988e+00  0.00000000e+00]\n",
            " [-1.66606888e+00  0.00000000e+00]\n",
            " [ 1.27698198e+00  1.00000000e+00]\n",
            " [-2.60721012e+00  0.00000000e+00]\n",
            " [-1.05914867e+00  1.00000000e+00]\n",
            " [-9.03993989e-01  1.00000000e+00]\n",
            " [-2.98199937e+00  0.00000000e+00]\n",
            " [-1.60152186e+00  0.00000000e+00]\n",
            " [-1.75344280e+00  1.00000000e+00]\n",
            " [-4.97244186e+00  1.00000000e+00]\n",
            " [ 4.52027417e-01  1.00000000e+00]\n",
            " [-3.62231678e+00  0.00000000e+00]\n",
            " [-9.54285585e-01  1.00000000e+00]\n",
            " [-1.51800589e+00  0.00000000e+00]\n",
            " [-6.57003396e-01  1.00000000e+00]\n",
            " [-3.88005438e+00  0.00000000e+00]\n",
            " [-2.61482329e+00  0.00000000e+00]\n",
            " [-1.92727903e+00  0.00000000e+00]\n",
            " [-4.89083006e+00  1.00000000e+00]\n",
            " [-1.38218711e+00  1.00000000e+00]\n",
            " [ 9.43724695e-01  1.00000000e+00]\n",
            " [-2.08867655e+00  0.00000000e+00]\n",
            " [-3.56058567e+00  0.00000000e+00]\n",
            " [-3.21092294e+00  0.00000000e+00]\n",
            " [-5.69064089e+00  1.00000000e+00]\n",
            " [-7.61903371e-01  1.00000000e+00]\n",
            " [-1.55932180e+00  0.00000000e+00]\n",
            " [-4.63831048e+00  1.00000000e+00]\n",
            " [ 1.14010130e+00  1.00000000e+00]\n",
            " [ 7.25753205e-01  1.00000000e+00]\n",
            " [-4.23644848e-01  1.00000000e+00]\n",
            " [-3.53922323e+00  0.00000000e+00]\n",
            " [-3.53976580e+00  0.00000000e+00]\n",
            " [-3.29908857e+00  0.00000000e+00]\n",
            " [-7.87583908e+00  1.00000000e+00]\n",
            " [-7.45584674e+00  1.00000000e+00]\n",
            " [-4.05409285e+00  0.00000000e+00]\n",
            " [-4.15472980e+00  0.00000000e+00]\n",
            " [-5.56170832e-01  1.00000000e+00]\n",
            " [-1.77022844e+00  1.00000000e+00]\n",
            " [-4.70937461e+00  1.00000000e+00]\n",
            " [-4.47254791e+00  0.00000000e+00]\n",
            " [-7.29743437e-01  0.00000000e+00]\n",
            " [-4.19245656e+00  1.00000000e+00]\n",
            " [-1.77217721e+00  1.00000000e+00]\n",
            " [-4.17469629e+00  1.00000000e+00]\n",
            " [-2.98052873e+00  0.00000000e+00]\n",
            " [-1.31794264e+00  1.00000000e+00]\n",
            " [ 2.92799509e-01  1.00000000e+00]\n",
            " [-1.62356229e+00  0.00000000e+00]\n",
            " [-3.51322386e+00  0.00000000e+00]\n",
            " [ 9.30366724e-01  1.00000000e+00]\n",
            " [-1.36242148e+00  1.00000000e+00]\n",
            " [-4.70674762e+00  1.00000000e+00]\n",
            " [ 2.42354820e+00  1.00000000e+00]\n",
            " [-6.61480668e+00  1.00000000e+00]\n",
            " [-2.22991737e+00  0.00000000e+00]\n",
            " [-3.42940428e+00  0.00000000e+00]\n",
            " [-1.67522600e+00  1.00000000e+00]\n",
            " [-1.31273891e+00  1.00000000e+00]\n",
            " [-1.11879934e+00  1.00000000e+00]\n",
            " [ 6.51803333e-01  1.00000000e+00]\n",
            " [-2.21609657e-01  1.00000000e+00]\n",
            " [-2.52058094e+00  0.00000000e+00]\n",
            " [-1.35470295e+00  1.00000000e+00]\n",
            " [-1.75225101e+00  0.00000000e+00]\n",
            " [-2.69637633e+00  0.00000000e+00]\n",
            " [-5.73806484e+00  1.00000000e+00]\n",
            " [-2.83125403e+00  0.00000000e+00]\n",
            " [-2.30131441e+00  0.00000000e+00]\n",
            " [-2.66151580e+00  0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wafCUVNb3ib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "ca895a4f-5a3d-45fc-8ab1-25698889a720"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(X[:, 0], np.zeros(len(X)), c=y)\n",
        "\n",
        "# plt.plot(x_test, clf.coef_ * x_test + clf.intercept_, linewidth=3)\n",
        "plt.title('Plot of Gaussian Quantile Dataset')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAE/CAYAAAAgxop3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfzUlEQVR4nO3ceZhcdZ3v8fenq3pLQjoJBAhJICigRkXQJiwi6ggIuIQZNxQ1jo7ozEVHxzsOyDyKuKGOO45jVEZEr6DikotyEVlFRekg+5aAMCEJIWQPnV6q6nv/OCdJpVLdvw5dSXXi5/U89eQsv3PO91Sd86lzzq86igjMzGxoLc0uwMxsrHNQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUG5i0i6QdI/7KJt/aOkFZI2Stp7V2xztPJan9HsOnYFSVdJmpcPv0PSzc2uyYbnoGwgSY9I2pSf9CskfVfShB1cxyxJIan4NGtoBb4InBwREyJiVZ02bZI+KukBSU9JWpqfvCc/nW02Ql7rwztj3ZKOk3SdpA2S1klaIOnZO2NbdbZ9vqTvV0+LiFMj4pIGrPsGSX35fq2XtFDSOZLad2AdIemQ0dYyVrazszgoG+81ETEBeCHQDfz7Lt7+fkAHcM8wbX4CzAXeDkwGDga+Arxqp1e3i0k6Fvg18AvgALJ9vRP4naRZzausYc6OiL2AacCHgDOAX0lSc8vaw0SEXw16AY8AJ1aNfx64Mh++AfiHfLiFLEAfBZ4Avgd05fP+BwhgY/46ts522oEvA8vy15fzaYcBT1Utf12dZU8ENgEzEvtyDvAQsAG4F/jbqnnnA9+vGp+Vb7OYj78DeDhf9i/Amfn0Q4AbgXXAk8DlVesI4JB8+FXAn4H1wBLg/Drbmpe/V08C5w2zH78F/rPO9KuA/66q9+aa+aOuBzgFGAAG88/jjjrHwjbbBp4NXAOsBh4A3jjMvm1ZT9W0A4Fe4NX5+BzgD8BaYDlwEdCWz7spr/2pvL43kX1xXgmsBNbkwzOq1l/3s83nvRO4L1/uauCgobbT7HN1h8/tZhewJ72oCkpgJtlV3Sfy8eqT453AYuAZwATgp8Cl+bzNJ15xmO1cANwC7AtMBX5ftZ1hlwcuBG4Ywb68gewKrCU/gZ4CpuXzzmeIoATGkwXKs/J504Dn5sM/BM7L19kBHF+1jupgehnw/Lzd4cAK4PSabX0L6AReAPQDz6mzD+OAMvDyOvP+HliaD7+D4YPyaddT+17VORa2bDt/75bktRWBI8mCd/YQn9GW9dRMvwn4bD78IuCYfH2zyILsA/X2Mx/fG3hd/t7tBfwY+HlVfUN9tnPJjunn5Nv6d+D3Q21nd3v51rvxfi5pLXAz2dXTp+u0ORP4YkQ8HBEbgXOBM3bgueSZwAUR8URErAQ+DrxthMvuAzy+eUTSFElr82d3fZunR8SPI2JZRFQi4nJgEdnVyUhUgOdJ6oyI5RGx+THAIHAQcEBE9EVE3U6MiLghIu7Kt30nWcC+tKbZxyNiU0TcAdxBFlC1ppCF2/I685aTfckkNbCelFcDj0TEf0dEKSL+DFxB9qW1I5aR7TsRsTAibsnX9wjwzTq1bxERqyLiiojojYgNwKdq2g/12b4X+ExE3BcRJbLj/ghJB+1g7WOSg7LxTo+ISRFxUET8U0RsqtPmALLb7s0eJfsW3m+E26i3/AEjXHYV2ZUAABGxOiImkV15bOkEkPR2SbfnIboWeB5ZyA4rIp4iuwJ9L7Bc0i+rOk4+DAj4k6R7JL2z3jokHS3pekkrJa3L11W77cerhnvJrsxrrSE7safVmTeN7GotqYH1pBwEHL35Pc/f9zOB/XdwPdPJbt2RdJikKyU9Lmk9WYAN+TlKGifpm5IezdvfBEySVEh8tgcBX6mqezXZZz19B2sfkxyUzbGM7MDa7ECgRHZLN5L/967e8stGuO1rgaMkzRiqQX4V8C3gbGDvPEjvJjvwIbsNH1e1yDYnckRcHREnkYXR/fm6iIjHI+LdEXEA8B7gP4foCf0/wAJgZkR0Af9Vte0Ry0/sP1D/iuyNZLeu2+2PpNpgGk09O/L/GC4Bbsy/aDe/JkTEP450BZJmkn3p/Taf9A2yz+DQiJgIfCRR+4eAZwFH5+1P2LxqGPqzzWt/T03tnRHx+5HWPpY5KJvjh8AHJR2c/3zo02QdGyWyh+gVsueXwy3/75KmStoH+Cjw/WHabxERvwauJ3tEcHT+U6FWsudYm40nO8FXAkj6e7Irys1uB06QdKCkLrJHB+Rt95M0V9J4smd1G/P9QdIbqgJ6Tb6NSp0y9wJWR0SfpDnAW0ayb0M4B5gn6f2S9pI0WdIngZew9bHIHcBzJR0hqYPsuWKj6lkBzJI0knPtSuAwSW+T1Jq/jpL0nNSC+ZXgS8l69/8E/Kqq9vXAxvzqrzZ0V7DtsbYXWWffWklTgI9VbWPIz5bsy+NcSc/N23ZJqv6Cqt3O7qXZD0n3pBc1vd41825g217vj5J9C68kC7nJVW0vyKevBY6ps64O4Ktkz9mW58Md+bxZpDuD2sjCYBHZbeJjZL3AJ1e1+RTZ7dOTZL/LvJGqjgPg63l9i4F3s7UzZxpbe7bX5vs9O1/mc8BSshPsIeCsqvVVd568nuxxwgay8LiIvEOk3v4xRKdG1fzj8zYb82WXkF0xVbc5L9/XJcBbG1UPWefIzWRfDLfVmf8Otu31fhbwy/zzXwVcBxwxzDHVl9e1gaxn/rzNx0Le5gSyK7+NZFeZF9Rs771kx9BasqvsA6reqwfJrvyTn22+rrcBd7H11wEXD7WdZp+rO/pSvhNmfxUkHU52Rf2WiLi62fXY7sG33vZXJbJe69OB5z/dv36yvz6+ojQzS/AVpZlZgoPSzCxht3xGs88++8SsWbOaXYaZ7WEWLlz4ZERs9xdbu2VQzpo1i56enmaXYWZ7GEmP1pvuW28zswQHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhyUZmYJDkozswQHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhyUZmYJDkozswQHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhyUZmYJDkozswQHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhoSlJJOkfSApMWSzqkzv13S5fn8P0qaVTP/QEkbJf3vRtRjZtZIow5KSQXg68CpwGzgzZJm1zR7F7AmIg4BvgR8tmb+F4GrRluLmdnO0IgryjnA4oh4OCIGgMuAuTVt5gKX5MM/AV4hSQCSTgf+AtzTgFrMzBquEUE5HVhSNf5YPq1um4goAeuAvSVNAP4N+HgD6jAz2yma3ZlzPvCliNiYaijpLEk9knpWrly58yszM8sVG7COpcDMqvEZ+bR6bR6TVAS6gFXA0cDrJX0OmARUJPVFxEW1G4mI+cB8gO7u7mhA3WZmI9KIoLwVOFTSwWSBeAbwlpo2C4B5wB+A1wPXRUQAL9ncQNL5wMZ6IWlm1kyjDsqIKEk6G7gaKAAXR8Q9ki4AeiJiAfAd4FJJi4HVZGFqZrZbUHZht3vp7u6Onp6eZpdhZnsYSQsjort2erM7c8zMxjwHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhyUZmYJDkozswQHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhyUZmYJDkozswQHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhyUZmYJDkozswQHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhyUZmYJDkozswQHpZlZgoPSzCzBQWlmluCgNDNLcFCamSU4KM3MEhyUZmYJDkozs4SGBKWkUyQ9IGmxpHPqzG+XdHk+/4+SZuXTT5K0UNJd+b9/04h6zMwaadRBKakAfB04FZgNvFnS7Jpm7wLWRMQhwJeAz+bTnwReExHPB+YBl462HjOzRmvEFeUcYHFEPBwRA8BlwNyaNnOBS/LhnwCvkKSI+HNELMun3wN0SmpvQE1mZg3TiKCcDiypGn8sn1a3TUSUgHXA3jVtXgfcFhH99TYi6SxJPZJ6Vq5c2YCyzcxGZkx05kh6Ltnt+HuGahMR8yOiOyK6p06duuuKM7O/eo0IyqXAzKrxGfm0um0kFYEuYFU+PgP4GfD2iHioAfWYmTVUI4LyVuBQSQdLagPOABbUtFlA1lkD8HrguogISZOAXwLnRMTvGlCLmVnDjToo82eOZwNXA/cBP4qIeyRdIOm1ebPvAHtLWgz8C7D5J0RnA4cAH5V0e/7ad7Q1mZk1kiKi2TXssO7u7ujp6Wl2GWa2h5G0MCK6a6ePic4cM7OxzEFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWUKxESuRdArwFaAAfDsiLqyZ3w58D3gRsAp4U0Q8ks87F3gXUAbeHxFXN6ImgCg/SWz6CZQfQa3d0PkqpM6h25ceydoPLsrKaZmOxr0Wtb2obvtK/x9h41eh8iS0HQcTPkBLoYuo9BKbroTSbVDph9IiYAA0AcprQEUozABaIdaBBK1HQcfJ0Ptj6L8mm04JaIe2v4GWCVC6ByhCDEBlDSig0gItHVCYDe0vgIFbofQgVDaAWqBlH2idndVXehj6roTKinzdlSHeiUnAJqAF1Al0QvFgaD+BO258hB9/6U+8/O9WcsxJ62hrh3IZ2tohAsqlbLOVMvRuFE9tKPCz+VPpuX4ie00p8+7zlvLAneO4/orJnDB3Hce9cj29G1u4/Gv7cs+t43j2kZs4eHYvNy2YxPJHO4AAlNelIeptpgBgr0kDvPVDK1i9oo0nlrUx7cB+uvYuc/NVXSy+s4P9Zg5y2pkrecXr1tLemb1HvRtE36YCe00s0TE+OwzqWb+6wK9/NJlHHujgsMM3ceIb1jBuQr3PrgUYBxoPsQEogiZDtIOezI6b4iwoPA9aBqF4JAzeBQM3QuWprD0Fsvc5suNKkyDWQOUJYDDfTke2HTbm+99OdiwNAl3QcXy2nsIU1Pk6VHwGldISWP8ZKD8IxWfBxI+gqGTnW+UJ1PYS6DgJqZWobCQ2/RxKd4Omg0pQWYFaXwSdr4YIYtMCKN0OhYPRuDeglilbP5GB27P5BOp8FbS+CA315o6QImJ0K5AKwIPAScBjwK3AmyPi3qo2/wQcHhHvlXQG8LcR8SZJs4EfAnOAA4DfAIdFRHm4bXZ3d0dPT8+wdcXgXcTqt0OUgH5gXPbB7X0Fapm8XfvKpqtg3b/lbavfkw4Y92ZaJp67bfv1n4LeS2rW0gaTfwDr3g+VtWRhs+f482/H84l3H8S3b3qAyVPLSFk4Vh+Dm8cjsteHX/8MFt05jr7eAsXWCqVBMaGrxHf/cD8Tuipb2gLcuKCLz73/QMqDotAalAdrb3iqQ3Ms2HqcnPP1R/nKh2dSLomB/hY6xpWZPLXE569YzO+umsS3LtiPS2+9f8v7Blv3e7N65/L/LGrng689hIH+Fgb6svV2TqjwtV8tYuoBg9svMKYUs9e4t0Pvt9j2vBLQmk8bBI2DwjNh0hdg9Vvy4K49fzqhpQuoZBcCbAI6QEU05Qeo9TlU1n8Ber/H1vO4A8a9kZaJ542oYkkLI6K7dnojbr3nAIsj4uGIGAAuA+bWtJkLbE6VnwCvUBbxc4HLIqI/Iv4CLM7XN2qx9l8hniJ7wwB6obyC2PC17dtGH6w/F+hj2w+TbFrvD4nBB7a2Ly2B3kvrbHUA1p4FlZXsaSEJcMTxT/GWf35im5O99uSunf7WD62gr7cAQCkPvrM+tmxLSG5uK8EJr1nHrGf1AaoTkjC2QhKyesTJZ6zme5+fxqanCgz0Z3X39RZYubyVn86fyilvXsX7Lly2zfsGW/d786ueL//rDJ5aX2Cgb+t6160qMv/j03byvjVCiez8mc/251UAA2y5So3e7M5r7fugspr658+m7G5om/OrD2Ijse5covQQ9H43n1fJt7EJei8nBu+ts76Ra0RQTgeWVI0/lk+r2yYiSsA6YO8RLrvDorwKyo/VmTMI/XXu7AduZ/i3YhD6r69qfxND3rbGGrIDZM908hmrhzypa7W0wOHHPIW07ZXEcaeur7sOCV5++pqG1LkrHfvKdTy5vHW76aWBFn575SRa24IXn7Z2xO/bluUH4b6e8URsu2ClLP507cTRlDxG9WWPjYZ8JARZ+NW5Cy49SPRdPcSyA0Tf9XWmj9xu05kj6SxJPZJ6Vq5cmWi8+ZK+nvY67duHaQ9QAHUMv46/EoMDO3bIlMva7hazNDh0YvRtKjydspqqUtr+NnqztvYKlTKUh9nnoagF1FJ/xcXW0T0yG7uebiQJ6CR7xlqriFo66kwfuUYE5VJgZtX4jHxa3TaSikAXWafOSJYFICLmR0R3RHRPnTp12ILUMhFaX8j2b1r2vGI7rYdnz0iGXiN0nFK1mhPrrDtXeAZ7apBWyvCDL+07ZCjUKpfg5l9NZNtb5uD/fnfvuuuIgF9fNoXhv7TGnisvmcqhL+ilpbDt1Ux7Z5nT3raKSkX8dP7UEb9vmxUK8OJT11Fs3Xa9be0VTnrj7nTlPdKY6YS2FwNtw7QpsP25V4S241Dnq6l/7Ag6Th1hDfU1IihvBQ6VdLCkNuAMYEFNmwXAvHz49cB1kfUiLQDOkNQu6WDgUOBPDagJTfo8FKZnPYB0Ah3Qfgwa/67t26qAJs8HdbFtyBWBNuj6NCrsv7V9yyTo+g+2e2amaTDlB9A2J9veDv2ooGX79Y0x9y4cz68vn8Ltvxu/pbNmuJda4MZfTKK9s0z7uDLF1grF1uCyr+7HA7d3bNu+At88f3/WrS5QKATtneX8lr321Wzb1/Tnmydw/GlrmXrAIJ0TynSMK9PWUeEFL97IaWeu4qvnTOfyi/bl3p7O5HtW630XLmXGM/vpHJ+tt2NcmcOO6OUd/7Z8lPux/aOCxipk5572gq6LyM6Hau3ApLzNuGy8cy5M+gq0Po8t52z+HDgb7oDW46B1Tj6/M1u+MBN1fQYVpkLX57J1aTwwPhue+ElUOGBUezPqXm8ASacBXyaL+osj4lOSLgB6ImKBpA7gUuBIYDVwRkQ8nC97HvBOsgd7H4iIq1LbG0mvN0BEBQb+AOVl0Po81PqcRPsB6L+JKC8HKlnvePtLUUtX3faV8oas57u8LPtpQ/vLtvwMIQbvhcF7CY2HwdsgNmW9eqX7gTYoPhtUgfJ6UBm1HU60Hgv9v4O+n8LgX7LOqJapMOHsbPnBhdAyJZteeRxC+XE0Lju4Wl8IA3/KfkZUWQXRBsXpUDwE2o5F5YeJvutg4M9Q6SV7EL6eLQ/dEWgGtM+B0kNAEQr7gwpQPBy1Hc761b1c9V8X09b2EC+b+yRSC+vXwP4z+wlgzYpW1FJm47oifX0FJuzVwrVXTOSO33dx6BGtnHbmEtY8MciNv5hM/6ZWjjpxHeueLPDjb0xloK/I7O5NTN5vgLtvaWP14wUG+0UA5dIQXySClhZRiaBYzDuNBrb+aKKl0EKlXNmm/fiuTgYHSgz0D2Y/SqtZX/YBQkuxBbWISqlM1Dz6Kra1MGX/djasLVEeKLH3/v0c/6pV7LNfhfVrixTbxrFxXZm7bmmjc1yFAw8tcdypa5j17A2IFlrbxbrVE+nv24upB6xhr4mbOyc6QPsDq7JvD9qIWM/df2xj6cMdzHpOH886oj8/zkpkX7Ct2c+4Yjy0HgKFfaD8EDAeijNBU6B0X/b8vP0EKByCYi3R+kIoPwKbfpUdL+rKfxnUSvZztvFQPBDKj8PAHRCPQxSheGh2HFYeympsmZF1xsSq7GdknW9ElRXZT9raX4rUTkSF6L0MBu+EtiNR5xuAMvT/Nuu8aTsKFQ/Kz8PI2pUeJAoHQpRRZSm0Phe1zs7Pr7th8P7sZ3Ztc5C2XvNFZT3035h9iO0nZBc2IzRUr3dDgnJXG2lQmpntiJ358yAzsz2ag9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzBAelmVmCg9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzBAelmVmCg9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzBAelmVmCg9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzBAelmVmCg9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzBAelmVnCqIJS0hRJ10halP87eYh28/I2iyTNy6eNk/RLSfdLukfShaOpxcxsZxntFeU5wLURcShwbT6+DUlTgI8BRwNzgI9VBep/RMSzgSOBF0s6dZT1mJk13GiDci5wST58CXB6nTavBK6JiNURsQa4BjglInoj4nqAiBgAbgNmjLIeM7OGG21Q7hcRy/Phx4H96rSZDiypGn8sn7aFpEnAa8iuSuuSdJakHkk9K1euHF3VZmY7oJhqIOk3wP51Zp1XPRIRISl2tABJReCHwFcj4uGh2kXEfGA+QHd39w5vx8zs6UoGZUScONQ8SSskTYuI5ZKmAU/UabYUeFnV+Azghqrx+cCiiPjyiCo2M9vFRnvrvQCYlw/PA35Rp83VwMmSJuedOCfn05D0SaAL+MAo6zAz22lGG5QXAidJWgScmI8jqVvStwEiYjXwCeDW/HVBRKyWNIPs9n02cJuk2yX9wyjrMTNrOEXsfo/7uru7o6enp9llmNkeRtLCiOiune6/zDEzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpbgoDQzS3BQmpklOCjNzBIclGZmCQ5KM7MEB6WZWYKD0swswUFpZpYwqqCUNEXSNZIW5f9OHqLdvLzNIknz6sxfIOnu0dRiZrazjPaK8hzg2og4FLg2H9+GpCnAx4CjgTnAx6oDVdLfARtHWYeZ2U4z2qCcC1ySD18CnF6nzSuBayJidUSsAa4BTgGQNAH4F+CTo6zDzGynGW1Q7hcRy/Phx4H96rSZDiypGn8snwbwCeALQO8o6zAz22mKqQaSfgPsX2fWedUjERGSYqQblnQE8MyI+KCkWSNofxZwFsCBBx440s2YmY1aMigj4sSh5klaIWlaRCyXNA14ok6zpcDLqsZnADcAxwLdkh7J69hX0g0R8TLqiIj5wHyA7u7uEQeymdlojfbWewGwuRd7HvCLOm2uBk6WNDnvxDkZuDoivhERB0TELOB44MGhQtLMrJlGG5QXAidJWgScmI8jqVvStwEiYjXZs8hb89cF+TQzs92CIna/u9ju7u7o6elpdhlmtoeRtDAiumun+y9zzMwSHJRmZgkOSjOzBAelmVmCg9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzBAelmVmCg9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzBAelmVmCg9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzBAelmVmCg9LMLMFBaWaW4KA0M0twUJqZJSgiml3DDpO0Eni0yWXsAzzZ5Bp2xO5Ur2vdOVxr2kERMbV24m4ZlGOBpJ6I6G52HSO1O9XrWncO1/r0+dbbzCzBQWlmluCgfPrmN7uAHbQ71etadw7X+jT5GaWZWYKvKM3MEhyUoyDpCEm3SLpdUo+kOc2uaTiS3ifpfkn3SPpcs+sZCUkfkhSS9ml2LUOR9Pn8fb1T0s8kTWp2TbUknSLpAUmLJZ3T7HqGImmmpOsl3Zsfp//c7JrAQTlanwM+HhFHAB/Nx8ckSS8H5gIviIjnAv/R5JKSJM0ETgb+p9m1JFwDPC8iDgceBM5tcj3bkFQAvg6cCswG3ixpdnOrGlIJ+FBEzAaOAf7XWKjVQTk6AUzMh7uAZU2sJeUfgQsjoh8gIp5ocj0j8SXgw2Tv85gVEb+OiFI+egswo5n11DEHWBwRD0fEAHAZ2ZfmmBMRyyPitnx4A3AfML25VTkoR+sDwOclLSG7QhtTVxI1DgNeIumPkm6UdFSzCxqOpLnA0oi4o9m17KB3Alc1u4ga04ElVeOPMQbCJ0XSLOBI4I/NrQSKzS5grJP0G2D/OrPOA14BfDAirpD0RuA7wIm7sr5qiVqLwBSy25mjgB9JekY08WcPiXo/QnbbPSYMV2tE/CJvcx7ZreMPdmVteyJJE4ArgA9ExPqm1+OfBz19ktYBkyIiJAlYFxETU8s1g6T/B3w2Iq7Pxx8CjomIlc2tbHuSng9cC/Tmk2aQPdaYExGPN62wYUh6B/Ae4BUR0ZtovktJOhY4PyJemY+fCxARn2lqYUOQ1ApcCVwdEV9sdj3gW+/RWga8NB/+G2BRE2tJ+TnwcgBJhwFtjNH/ICEi7oqIfSNiVkTMIrtVfOEYDslTyJ6lvnashWTuVuBQSQdLagPOABY0uaa68guO7wD3jZWQBN96j9a7ga9IKgJ9wFlNrmc4FwMXS7obGADmNfO2ew9zEdAOXJOd59wSEe9tbklbRURJ0tnA1UABuDgi7mlyWUN5MfA24C5Jt+fTPhIRv2piTb71NjNL8a23mVmCg9LMLMFBaWaW4KA0M0twUJqZJTgozcwSHJRmZgkOSjOzhP8Pa0vmIU1Ox/4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAp-oGwPaoDF",
        "colab_type": "text"
      },
      "source": [
        "Above is a plot of the dataset we created. Yellow dots are class 1 and purple dots are class 0.\n",
        "### i.a.) Comment on how do you think logistic regression will perform when trying to classify this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOvRdYaXc1n8",
        "colab_type": "text"
      },
      "source": [
        "A logistic regression will likely not work the best with this dataset unless you transform the data. Will be difficult to pass a line through the dataset with a lot of accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RktzTWbFviPd",
        "colab_type": "text"
      },
      "source": [
        "### i.b.) Implement Logistic Regression\n",
        "Implement logistic regression using scikit learn on the dataset we created and train the model. You may refer to https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html for more information on scikit learn logistic regression. \\\\\n",
        "** Hint: look up in the documentation how you can adjust the penalty parameter to 'l2' or 'l1' regularization, the parameter C (the same as $\\lambda$ in linear regression), or adjusting max_iter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gml2kLo_qwBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGi4jjA3vj8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "273367e8-f551-4e2b-d072-6e27b5159612"
      },
      "source": [
        "#YOUR CODE HERE use the sklearn train test split function to generate the training and test sets.\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "#YOUR CODE HERE Call logistic regression form sklearn\n",
        "clf = LogisticRegression(penalty='l1', solver='liblinear', C=0.25, max_iter=100,).fit(X, y)\n",
        "print('Training Score: ', clf.score(x_train, y_train))\n",
        "print('Testing Score: ', clf.score(x_test, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Score:  0.735\n",
            "Testing Score:  0.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPR9gDyn3rWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "4b1e4e19-832d-411f-ebe4-bf9b80a57bf7"
      },
      "source": [
        "# Plot results\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.scatter(X[:, 0], np.zeros(len(X)), c=y)\n",
        "\n",
        "plt.plot(x_test, clf.coef_ * x_test + clf.intercept_, linewidth=3)\n",
        "plt.title('Plot of Gaussian Quantile Dataset and Regression Line')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR8VhvdacoU6",
        "colab_type": "text"
      },
      "source": [
        "### i.c) How did we do?\n",
        "\n",
        "Please comment on the performance of the model you trained on training and test sets. Did you try adjusting the parameters? If so, did they help?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZyM3fMFcuw7",
        "colab_type": "text"
      },
      "source": [
        "The performance of the model I trained was not as good as it could be with an accuracy in the low 70's%. Changing the penalty from l2 to l1 (also had to adjust solver to 'liblinear') seemed to make the scores for both test and training better by about 5%. Additionally, adjusting the C value to around 0.25 seemed to raise the score by another 10% or so. Lastly, adjusting the max iter did not seem to have a major impact on the scores. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uXK2snqx1xp",
        "colab_type": "text"
      },
      "source": [
        "## ii) Polynomial Transformation + Sign Classification\n",
        "Let's try some other models and see if they perform better. Recall from lecture the Binary \"Sign\" Classifier:\n",
        "$$\\begin{align}\n",
        "f(x)= sign({\\bf{\\theta}}\\cdot\\phi(x))=\\begin{cases} \n",
        "          1 & 0\\leq {\\bf{\\theta}} \\cdot\\phi(x)  \\\\\n",
        "          0 & {\\bf{\\theta}} \\cdot\\phi(x) < 0\n",
        "            \\end{cases}\n",
        "\\end{align}\n",
        "$$\n",
        "We will now use Binary Sign Classifier, along with polynomial and horizontal translation in order to learn out dataset. In the next couple of sections we will illustrate how to use polynomial and horizontal translation in order use the Sign Binary Classifier. \\\\\n",
        "** Note that we will classify an example as 1 if $0\\leq {\\bf{\\theta}} \\cdot\\phi(x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMY0DB7X55aO",
        "colab_type": "text"
      },
      "source": [
        "### Polynomial transformation example\n",
        "Let us first generate an example dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwXT-VFblzu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create example data\n",
        "example_data = np.arange(-3,3,0.1).reshape(-1,1)\n",
        "# We will create some example labels. y=1 if x<-1 and 1<x and 0 otherwise\n",
        "example_y = np.array([1 if 1<x or x<-1 else 0 for x in example_data])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWjcOZoD0c-T",
        "colab_type": "text"
      },
      "source": [
        "From the plot below, we can see that this second data set is much like the dataset in part i."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUAkH7xr0oUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "8eb29e8e-9f18-409c-f328-e885ec7a120b"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(np.arange(-3,3,0.1).reshape(-1,1),np.zeros(len(example_data)), c=example_y)\n",
        "plt.title('Plot of Example Dataset')\n",
        "plt.show"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFEDJXim05Wn",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll now begin implementing the polynomial transformation. We begin by using scikit learn to carry polynomial transform on an example dataset. We'll also define the score variable $\\hat{y_i}={\\bf{\\theta}}\\cdot\\phi(x)$ as:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat{y_i}={\\bf{\\theta}}\\cdot\\phi(x_i) &= \\theta_{0} + \\theta_{1} \\phi_1(x_i)+\\theta_{2} \\phi_2(x_i)+...+\\theta_{d} \\phi_d(x_i) \\\\\n",
        "&=\\theta_{0} + \\theta_{1} x_i+\\theta_{2} x_i^2+...+\\theta_{d} x_i^d\n",
        "\\end{align}\n",
        "$$\n",
        "where $i$ is the sample number $\\phi_j(x)=x^j$, where $j$ is a power, and ${\\bf{\\theta}}$ is a weight vector that is the length of $d$ (more on ${\\bf{\\theta}}$ later). To tie it all back together, the $i^{th}$ sample will be labelled as 1 if $0 \\leq \\hat{y}_i$ and 0 if $0>\\hat{y}_i$.\n",
        "\n",
        "\\\\\n",
        "\n",
        "The first step will then be to compute the polynomial transform. Our data is in the form\n",
        "$$X =\n",
        "\\begin{bmatrix}\n",
        "    x_{1}\\\\\n",
        "    x_{2}\\\\\n",
        "    \\vdots \\\\\n",
        "    x_{n} \n",
        "\\end{bmatrix}$$\n",
        "Using second degree polynomials we transform it into:\n",
        "$$X =\\begin{bmatrix}\n",
        "    1&x_{1} & x_{1}^2\\\\\n",
        "    1&x_{2}& x_{2}^2\\\\\n",
        "    \\vdots & \\vdots & \\vdots \\\\\n",
        "    1&x_{n}& x_{n}^2\n",
        "\\end{bmatrix}$$\n",
        "More information here on scikit learn polynomial transformation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XReiMjGk12N9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(2) # We will use a polynomial of 2nd degree for this example."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCddEA3g4NaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next we fit the polynomial transform\n",
        "example_X = poly.fit_transform(example_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viAyi8iNhPQG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7972ecf0-0c97-4c23-a7af-06694e71cab1"
      },
      "source": [
        "example_data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.00000000e+00],\n",
              "       [-2.90000000e+00],\n",
              "       [-2.80000000e+00],\n",
              "       [-2.70000000e+00],\n",
              "       [-2.60000000e+00],\n",
              "       [-2.50000000e+00],\n",
              "       [-2.40000000e+00],\n",
              "       [-2.30000000e+00],\n",
              "       [-2.20000000e+00],\n",
              "       [-2.10000000e+00],\n",
              "       [-2.00000000e+00],\n",
              "       [-1.90000000e+00],\n",
              "       [-1.80000000e+00],\n",
              "       [-1.70000000e+00],\n",
              "       [-1.60000000e+00],\n",
              "       [-1.50000000e+00],\n",
              "       [-1.40000000e+00],\n",
              "       [-1.30000000e+00],\n",
              "       [-1.20000000e+00],\n",
              "       [-1.10000000e+00],\n",
              "       [-1.00000000e+00],\n",
              "       [-9.00000000e-01],\n",
              "       [-8.00000000e-01],\n",
              "       [-7.00000000e-01],\n",
              "       [-6.00000000e-01],\n",
              "       [-5.00000000e-01],\n",
              "       [-4.00000000e-01],\n",
              "       [-3.00000000e-01],\n",
              "       [-2.00000000e-01],\n",
              "       [-1.00000000e-01],\n",
              "       [ 2.66453526e-15],\n",
              "       [ 1.00000000e-01],\n",
              "       [ 2.00000000e-01],\n",
              "       [ 3.00000000e-01],\n",
              "       [ 4.00000000e-01],\n",
              "       [ 5.00000000e-01],\n",
              "       [ 6.00000000e-01],\n",
              "       [ 7.00000000e-01],\n",
              "       [ 8.00000000e-01],\n",
              "       [ 9.00000000e-01],\n",
              "       [ 1.00000000e+00],\n",
              "       [ 1.10000000e+00],\n",
              "       [ 1.20000000e+00],\n",
              "       [ 1.30000000e+00],\n",
              "       [ 1.40000000e+00],\n",
              "       [ 1.50000000e+00],\n",
              "       [ 1.60000000e+00],\n",
              "       [ 1.70000000e+00],\n",
              "       [ 1.80000000e+00],\n",
              "       [ 1.90000000e+00],\n",
              "       [ 2.00000000e+00],\n",
              "       [ 2.10000000e+00],\n",
              "       [ 2.20000000e+00],\n",
              "       [ 2.30000000e+00],\n",
              "       [ 2.40000000e+00],\n",
              "       [ 2.50000000e+00],\n",
              "       [ 2.60000000e+00],\n",
              "       [ 2.70000000e+00],\n",
              "       [ 2.80000000e+00],\n",
              "       [ 2.90000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVPutfv5hK_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0764962-0ea1-47da-ef77-568b92490da5"
      },
      "source": [
        "example_X "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00000000e+00, -3.00000000e+00,  9.00000000e+00],\n",
              "       [ 1.00000000e+00, -2.90000000e+00,  8.41000000e+00],\n",
              "       [ 1.00000000e+00, -2.80000000e+00,  7.84000000e+00],\n",
              "       [ 1.00000000e+00, -2.70000000e+00,  7.29000000e+00],\n",
              "       [ 1.00000000e+00, -2.60000000e+00,  6.76000000e+00],\n",
              "       [ 1.00000000e+00, -2.50000000e+00,  6.25000000e+00],\n",
              "       [ 1.00000000e+00, -2.40000000e+00,  5.76000000e+00],\n",
              "       [ 1.00000000e+00, -2.30000000e+00,  5.29000000e+00],\n",
              "       [ 1.00000000e+00, -2.20000000e+00,  4.84000000e+00],\n",
              "       [ 1.00000000e+00, -2.10000000e+00,  4.41000000e+00],\n",
              "       [ 1.00000000e+00, -2.00000000e+00,  4.00000000e+00],\n",
              "       [ 1.00000000e+00, -1.90000000e+00,  3.61000000e+00],\n",
              "       [ 1.00000000e+00, -1.80000000e+00,  3.24000000e+00],\n",
              "       [ 1.00000000e+00, -1.70000000e+00,  2.89000000e+00],\n",
              "       [ 1.00000000e+00, -1.60000000e+00,  2.56000000e+00],\n",
              "       [ 1.00000000e+00, -1.50000000e+00,  2.25000000e+00],\n",
              "       [ 1.00000000e+00, -1.40000000e+00,  1.96000000e+00],\n",
              "       [ 1.00000000e+00, -1.30000000e+00,  1.69000000e+00],\n",
              "       [ 1.00000000e+00, -1.20000000e+00,  1.44000000e+00],\n",
              "       [ 1.00000000e+00, -1.10000000e+00,  1.21000000e+00],\n",
              "       [ 1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.00000000e+00, -9.00000000e-01,  8.10000000e-01],\n",
              "       [ 1.00000000e+00, -8.00000000e-01,  6.40000000e-01],\n",
              "       [ 1.00000000e+00, -7.00000000e-01,  4.90000000e-01],\n",
              "       [ 1.00000000e+00, -6.00000000e-01,  3.60000000e-01],\n",
              "       [ 1.00000000e+00, -5.00000000e-01,  2.50000000e-01],\n",
              "       [ 1.00000000e+00, -4.00000000e-01,  1.60000000e-01],\n",
              "       [ 1.00000000e+00, -3.00000000e-01,  9.00000000e-02],\n",
              "       [ 1.00000000e+00, -2.00000000e-01,  4.00000000e-02],\n",
              "       [ 1.00000000e+00, -1.00000000e-01,  1.00000000e-02],\n",
              "       [ 1.00000000e+00,  2.66453526e-15,  7.09974815e-30],\n",
              "       [ 1.00000000e+00,  1.00000000e-01,  1.00000000e-02],\n",
              "       [ 1.00000000e+00,  2.00000000e-01,  4.00000000e-02],\n",
              "       [ 1.00000000e+00,  3.00000000e-01,  9.00000000e-02],\n",
              "       [ 1.00000000e+00,  4.00000000e-01,  1.60000000e-01],\n",
              "       [ 1.00000000e+00,  5.00000000e-01,  2.50000000e-01],\n",
              "       [ 1.00000000e+00,  6.00000000e-01,  3.60000000e-01],\n",
              "       [ 1.00000000e+00,  7.00000000e-01,  4.90000000e-01],\n",
              "       [ 1.00000000e+00,  8.00000000e-01,  6.40000000e-01],\n",
              "       [ 1.00000000e+00,  9.00000000e-01,  8.10000000e-01],\n",
              "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.00000000e+00,  1.10000000e+00,  1.21000000e+00],\n",
              "       [ 1.00000000e+00,  1.20000000e+00,  1.44000000e+00],\n",
              "       [ 1.00000000e+00,  1.30000000e+00,  1.69000000e+00],\n",
              "       [ 1.00000000e+00,  1.40000000e+00,  1.96000000e+00],\n",
              "       [ 1.00000000e+00,  1.50000000e+00,  2.25000000e+00],\n",
              "       [ 1.00000000e+00,  1.60000000e+00,  2.56000000e+00],\n",
              "       [ 1.00000000e+00,  1.70000000e+00,  2.89000000e+00],\n",
              "       [ 1.00000000e+00,  1.80000000e+00,  3.24000000e+00],\n",
              "       [ 1.00000000e+00,  1.90000000e+00,  3.61000000e+00],\n",
              "       [ 1.00000000e+00,  2.00000000e+00,  4.00000000e+00],\n",
              "       [ 1.00000000e+00,  2.10000000e+00,  4.41000000e+00],\n",
              "       [ 1.00000000e+00,  2.20000000e+00,  4.84000000e+00],\n",
              "       [ 1.00000000e+00,  2.30000000e+00,  5.29000000e+00],\n",
              "       [ 1.00000000e+00,  2.40000000e+00,  5.76000000e+00],\n",
              "       [ 1.00000000e+00,  2.50000000e+00,  6.25000000e+00],\n",
              "       [ 1.00000000e+00,  2.60000000e+00,  6.76000000e+00],\n",
              "       [ 1.00000000e+00,  2.70000000e+00,  7.29000000e+00],\n",
              "       [ 1.00000000e+00,  2.80000000e+00,  7.84000000e+00],\n",
              "       [ 1.00000000e+00,  2.90000000e+00,  8.41000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMJ-_rSWvGuk",
        "colab_type": "text"
      },
      "source": [
        "Next, we compute the vector $\\hat{y}=\\phi(x) {\\bf{\\theta}}$ by multiplying the matrices $\\phi(x)$ and ${\\bf{\\theta}}$. ${\\bf{\\theta}}$ is a weight vector that determines the value of the bias and the scale of the polynomial transformations. We will manually adjust these values to try to get a good fit using Binary Sign Classification model. The plus side of using ${\\bf{\\theta}}$ is that we can drop unwanted terms from prediction $h_i=sign(\\hat{y}_i)$. For example we will implement computing the array of scores $\\hat{y}$ as\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat{y}=\\phi(x) {\\bf{\\theta}}= \\begin{bmatrix}\n",
        "    1&x_{1} & x_{1}^2\\\\\n",
        "    1&x_{2}& x_{2}^2\\\\\n",
        "    \\vdots & \\vdots & \\vdots \\\\\n",
        "    1&x_{n}& x_{n}^2\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "    0\\\\\n",
        "    0\\\\\n",
        "    1\n",
        "\\end{bmatrix}=\\begin{bmatrix}\n",
        "     x_{1}^2\\\\\n",
        "     x_{2}^2\\\\\n",
        "    \\vdots\\\\\n",
        "     x_{n}^2\n",
        "\\end{bmatrix}\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhWO2pnt31q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We compute y_hat\n",
        "theta = np.array([0,0,1])\n",
        "y_hat = np.matmul(example_X,theta)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZdO9U7C0Kih",
        "colab_type": "text"
      },
      "source": [
        "Now we'll plot our data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aLT9gLn4Kd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "7f4f866d-9501-4a8d-9373-dce79c41ab30"
      },
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(np.arange(-3,3,0.1).reshape(-1,1) ,y_hat, c=example_y)\n",
        "plt.title('Plot of Polynomial Transformation of Example Dataset')\n",
        "plt.show"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpqZB0AE1w8i",
        "colab_type": "text"
      },
      "source": [
        "We can see that if we simply move this new curve down, we classify most of the examples correctly using the Binary Sign classifier. We'll do so by adjusting ${\\bf{\\theta}}$ so that the second degree polynomial term is moved down slightly by calculating:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat{y}=\\phi(x) {\\bf{\\theta}}= \\begin{bmatrix}\n",
        "    1&x_{1} & x_{1}^2\\\\\n",
        "    1&x_{2}& x_{2}^2\\\\\n",
        "    \\vdots & \\vdots & \\vdots \\\\\n",
        "    1&x_{n}& x_{n}^2\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "    -0.9\\\\\n",
        "    0\\\\\n",
        "    1\n",
        "\\end{bmatrix}=\\begin{bmatrix}\n",
        "     x_{1}^2-0.9\\\\\n",
        "     x_{2}^2-0.9\\\\\n",
        "    \\vdots\\\\\n",
        "     x_{n}^2\n",
        "-0.9\\end{bmatrix}\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vgMGnRp4hrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "cdc52a6d-ad4c-41a8-b3fd-bddcea85ee47"
      },
      "source": [
        "# Change the weight value\n",
        "theta = np.array([-0.9,0,1])\n",
        "\n",
        "# Compute y_hat\n",
        "y_hat = np.matmul(example_X,theta)\n",
        "\n",
        "# Plot\n",
        "import matplotlib.patches as mpatches\n",
        "plt.figure(figsize=(8,8))\n",
        "arr1 = plt.scatter(np.arange(-3,3,0.1).reshape(-1,1) ,y_hat, c=example_y)\n",
        "y_lim = plt.ylim()\n",
        "x_lim = plt.xlim()\n",
        "arr2 = plt.plot(x_lim, (0,0), 'k-', color = 'r')\n",
        "plt.ylim(y_lim)\n",
        "plt.xlim(x_lim)\n",
        "plt.legend([arr1, arr2], ['u','v'])\n",
        "red_patch = mpatches.Patch(color='red', label='Y-axis',linestyle ='-')\n",
        "plt.legend(handles=[red_patch],loc='lower right', frameon=False)\n",
        "plt.title('Plot of Polynomial Transformation of Example Dataset with y=0 decision boundary')\n",
        "plt.show"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jblJfUpRAfFt",
        "colab_type": "text"
      },
      "source": [
        "We can now see that if we were to classify the datapoints by the sign of $y_i$ that most of the data points would be correctly classified as those below the y-axis would be classified as 0 while the rest would be classified as 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvrmtQYo8eg_",
        "colab_type": "text"
      },
      "source": [
        "### Second transformation example:\n",
        "In addition to implementing a polynomial transformation and moving it up or down, we can also move the transformation right or left using a simple yet tricky transformation. Recall that a function $f(x)$ can be moved right $q$ units by computing $f(x-q)$ or to the left by $q$ computing $f(x+q)$. We can also move the polynomial transform left or right in a similar fashion by letting $\\phi_j(x)=(x-q)^j$. Now we want to implement a right transform by choosing $q = 2$, carrying out a polynomial transforms, and shifting polynomial transforms down by 0.9. So to begin, we first want to transform the example_dataset into:\n",
        "\n",
        "$$X =\\begin{bmatrix}\n",
        "    1&(x_{1}-2) & (x_{1}-2)^2\\\\\n",
        "    1&(x_{2}-2)& (x_{2}-2)^2\\\\\n",
        "    \\vdots & \\vdots & \\vdots \\\\\n",
        "    1&(x_{n}-2)& (x_{n}-2)^2\n",
        "\\end{bmatrix}$$\n",
        "This should move our transformed value over to the right 2 units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSWSKXBXB1RK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "11e331c9-90b2-40df-b48b-3b1bf40eaeeb"
      },
      "source": [
        "# First subtract 2 from each row in example_data\n",
        "example_X = example_data-2\n",
        "\n",
        "# Compute the 2nd degree polynomial transform\n",
        "example_X = poly.fit_transform(example_X)\n",
        "\n",
        "# Compute new y_hat with same theta as before\n",
        "theta = np.array([-0.9,0,1])\n",
        "y_hat = np.matmul(example_X,theta)\n",
        "\n",
        "# Plot\n",
        "import matplotlib.patches as mpatches\n",
        "plt.figure(figsize=(8,8))\n",
        "arr1 = plt.scatter(np.arange(-3,3,0.1).reshape(-1,1) ,y_hat, c=example_y)\n",
        "y_lim = plt.ylim()\n",
        "x_lim = plt.xlim()\n",
        "arr2 = plt.plot(x_lim, (0,0), 'k-', color = 'r')\n",
        "plt.ylim(y_lim)\n",
        "plt.xlim(x_lim)\n",
        "plt.legend([arr1, arr2], ['u','v'])\n",
        "red_patch = mpatches.Patch(color='red', label='Y-axis',linestyle ='-')\n",
        "plt.legend(handles=[red_patch],loc='lower right', frameon=False)\n",
        "plt.title('Plot of Polynomial and Linear Transformation of Example Dataset with y=0 decision boundary')\n",
        "plt.show"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv3sGrLPEeOw",
        "colab_type": "text"
      },
      "source": [
        "You can see that the parabola now begins at 2, rather than zero, and is shifted down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xKMyeOheZ4ok"
      },
      "source": [
        "## Binary Sign Classification on dataset from part (i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-9gBKzO9Z4om"
      },
      "source": [
        "### ii.a) How do you think a sign classification plus transformation model will perform on the Gaussian Quantile data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2oMWoVCf3Eq",
        "colab_type": "text"
      },
      "source": [
        "A binary sign classification plus transformation model should perform much better than the model we made before. The sign classification's assignment of either 1 or 0 will be an accurate way of analyzing the data, especially once the horizontal and vertical transformations are made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQlTvvq5gIp1",
        "colab_type": "text"
      },
      "source": [
        "### ii.b) Implementation\n",
        "Now, you will implement a Binary Sign Classification model to transform the linear data from part (i) as well as implement the helper functions to compute $\\hat{y}$, the class prediction, and the model accuracy. Then you will use the methods outlined above to transform the data into a new form for classification. For this example, we will just run our model on all of the data x and y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LUcMlsW6LXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement these helper functions\n",
        "\n",
        "def generate_h(y):\n",
        "    \"\"\"\n",
        "    Generates the class prediction h[i]=1 if y[i]>0 or h[i]=0 if y[i]<0\n",
        "    args:\n",
        "        y: a numpy array of y values\n",
        "    return: a (500,1) array of 1 and 0s indicating class prediction\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE h[i]=1 if y[i]>0 or h[i]=0 if y[i]<0\n",
        "    h = np.array([[1] if 0<=i else [0] for i in y])\n",
        "    return h\n",
        "\n",
        "\n",
        "def compute_accuracy(y, h): \n",
        "    \"\"\"\n",
        "    computes the accuracy of the model. (h-y)/len(y)\n",
        "    args:\n",
        "        y: true class label\n",
        "        h: predicted labels\n",
        "    return: the accuracy.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    x = np.transpose(y)\n",
        "    temp = (h-y)\n",
        "    temp = np.count_nonzero(temp)\n",
        "    temp = 500 - temp\n",
        "    accuracy = temp / len(y) * 100\n",
        "    return accuracy"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oToQ8vyoJ7eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Impelement your data transformation using scikit learn polynomial\n",
        "# CHOOSE VALUE choose a degree for polynomial transformation\n",
        "polynomial_degree = 4\n",
        "# CHOOSE VALUE choose a value for horizontal shift\n",
        "q = -3\n",
        "poly = PolynomialFeatures(polynomial_degree)\n",
        "X_tf = X.reshape(-1,1) # Don't change\n",
        "X_tf = poly.fit_transform(X_tf-q)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH6Grdu06iRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fb4eeb9-b485-40df-f394-e64bc099d5b3"
      },
      "source": [
        "# Compute y_hat\n",
        "theta = np.array([-.9, -.2,.5,.1,.01]) # ADJUST THESE WEIGHTS. The length of w needs to be the same as the degree of polynomial+1,\n",
        "# Either delete a poly-term or scale it, shift the transformed values up or down\n",
        "\n",
        "y_hat = np.matmul(X_tf,theta) # Compute y_hat's\n",
        "\n",
        "# Run sign model\n",
        "h = generate_h(y_hat)\n",
        "accuracy = compute_accuracy(y,h)\n",
        "print(f\"accuracy= {accuracy}%\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy= 91.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-z4eQyFkOmJ",
        "colab_type": "text"
      },
      "source": [
        "### Plotting data against y=0\n",
        "The plotting function below may be helpful for visualizing the data against the decision boundary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqLAigsy90lx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "58b5627e-4f2e-47e4-ab27-bade14d5b59c"
      },
      "source": [
        "# Plot\n",
        "import matplotlib.patches as mpatches\n",
        "plt.figure(figsize=(8,8))\n",
        "arr1 = plt.scatter(X ,y_hat, c=y)\n",
        "y_lim = plt.ylim()\n",
        "x_lim = plt.xlim()\n",
        "arr2 = plt.plot(x_lim, (0,0), 'k-', color = 'r')\n",
        "plt.ylim(y_lim)\n",
        "plt.xlim(x_lim)\n",
        "red_patch = mpatches.Patch(color='red', label='Y-axis',linestyle ='-')\n",
        "plt.legend(handles=[red_patch],loc='lower right', frameon=False)\n",
        "plt.title('Plot of Gaussian Quantile Dataset with y=0 decision boundary')\n",
        "plt.show"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlY2OhtBkoKd",
        "colab_type": "text"
      },
      "source": [
        "### ii.c) How did we do?\n",
        "\n",
        "Please comment on the performance of the model you created on classifying the dataset. What transformation parameters did you use? What was your ${\\bf{\\theta}}$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwQpIqaMk_6q",
        "colab_type": "text"
      },
      "source": [
        "The performance of the model I created was much more accurate than the previous model with an accuracy of 91%. Being able to transform the parameters was key in increasing the accuracy of the model. Switching the polynomial degree to 4 and increasing the theta weights and length of w added much of the additional accuracy. In this case, the theta was an np array of the following weights, [-.9, -.2,.5,.1,.01]. Adjusting the horizontal transformation (q) to -3 also allowed the model to separate and capture more of the data accurately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBWHO4vUlH11",
        "colab_type": "text"
      },
      "source": [
        "##iii) Artificial Neural Network\n",
        "Next, we will use tensorflow to create an artificial neural network to classify the Gaussian Quantile dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9F-L3kSpNkH",
        "colab_type": "text"
      },
      "source": [
        "### iii.a) Build a Neural Network to feed in the Gaussian Quantile data\n",
        "\n",
        "Below, define a neural network with the following layers:\n",
        "<ul>\n",
        "<li>Input Layer</li>\n",
        "<li>Dense Layer with 15 neurons, choose whatever activation you think is suitable</li>\n",
        "<li>Dense Layer with 5 neurons, choose whatever activation you think is suitable</li>\n",
        "<li>Dense Layer with 1 neuron, choose whatever activation you think is suitable</li>\n",
        "<li> Dense layer with 1 neuron for classification (what activation do we need to use?)</li>\n",
        "</ul>\n",
        "\n",
        "Then, run model.summary(), compile, then fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sisivBeulTnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense # Only use these layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import * \n",
        "\n",
        "# BUILD NETWORK HERE\n",
        "def build_model1():\n",
        "    input_layer = Input(shape=(1))\n",
        "    x = Dense(15, activation='tanh')(input_layer)\n",
        "    x = Dense(5, activation='tanh')(x)\n",
        "    x = Dense(1, activation='tanh')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    return Model(input_layer, x)\n",
        "\n",
        "model = build_model1()\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziQ3FIx7nR1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "fa7551ec-dcc6-4846-e77c-a498e52da9d7"
      },
      "source": [
        "# Show a summary of your model\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 15)                30        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 80        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 6         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 118\n",
            "Trainable params: 118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV2c-DPNnYSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile your model with the chosen optimizer, binary cross entropy for the loss, and accuracy as the metric\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer,loss='bce',metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv2DgeWUnY6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c2832a5-5ef7-4d5a-d93e-36a527c274bf"
      },
      "source": [
        "# Call fit on your model passing in the X, y data above, train for 100 epochs\n",
        "hist = model.fit(X, y, epochs=100, validation_split=0.2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 0.7011 - accuracy: 0.5975 - val_loss: 0.7046 - val_accuracy: 0.6100\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.6925 - val_loss: 0.6827 - val_accuracy: 0.7200\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.7350 - val_loss: 0.6679 - val_accuracy: 0.6900\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.7150 - val_loss: 0.6579 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.7000 - val_loss: 0.6468 - val_accuracy: 0.7100\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.7275 - val_loss: 0.6320 - val_accuracy: 0.6900\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.7325 - val_loss: 0.6224 - val_accuracy: 0.7200\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.7175 - val_loss: 0.6111 - val_accuracy: 0.7200\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.7275 - val_loss: 0.5976 - val_accuracy: 0.7000\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7100 - val_loss: 0.5916 - val_accuracy: 0.7200\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7275 - val_loss: 0.5756 - val_accuracy: 0.6900\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7250 - val_loss: 0.5685 - val_accuracy: 0.7200\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7075 - val_loss: 0.5591 - val_accuracy: 0.7300\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7575 - val_loss: 0.5476 - val_accuracy: 0.7900\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7325 - val_loss: 0.5433 - val_accuracy: 0.7400\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7675 - val_loss: 0.5297 - val_accuracy: 0.8400\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.8025 - val_loss: 0.5236 - val_accuracy: 0.7600\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7825 - val_loss: 0.5147 - val_accuracy: 0.8300\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.8000 - val_loss: 0.5071 - val_accuracy: 0.8300\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.8425 - val_loss: 0.4986 - val_accuracy: 0.8500\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.8350 - val_loss: 0.4945 - val_accuracy: 0.8100\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7825 - val_loss: 0.4860 - val_accuracy: 0.8400\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.8475 - val_loss: 0.4782 - val_accuracy: 0.8700\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.8150 - val_loss: 0.4735 - val_accuracy: 0.8200\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8425 - val_loss: 0.4660 - val_accuracy: 0.8700\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.8275 - val_loss: 0.4609 - val_accuracy: 0.8300\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.8350 - val_loss: 0.4537 - val_accuracy: 0.8800\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8350 - val_loss: 0.4488 - val_accuracy: 0.8700\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8650 - val_loss: 0.4422 - val_accuracy: 0.8800\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.8375 - val_loss: 0.4378 - val_accuracy: 0.8700\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8700 - val_loss: 0.4312 - val_accuracy: 0.9100\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8775 - val_loss: 0.4303 - val_accuracy: 0.8400\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8325 - val_loss: 0.4212 - val_accuracy: 0.8800\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8725 - val_loss: 0.4172 - val_accuracy: 0.8800\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8325 - val_loss: 0.4131 - val_accuracy: 0.8800\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8825 - val_loss: 0.4076 - val_accuracy: 0.9100\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8750 - val_loss: 0.4061 - val_accuracy: 0.8700\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8600 - val_loss: 0.3982 - val_accuracy: 0.9100\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8800 - val_loss: 0.3937 - val_accuracy: 0.9000\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8775 - val_loss: 0.3917 - val_accuracy: 0.8800\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8400 - val_loss: 0.3865 - val_accuracy: 0.9000\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8825 - val_loss: 0.3825 - val_accuracy: 0.9100\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8825 - val_loss: 0.3788 - val_accuracy: 0.9000\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8725 - val_loss: 0.3752 - val_accuracy: 0.9100\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8900 - val_loss: 0.3712 - val_accuracy: 0.9100\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8775 - val_loss: 0.3681 - val_accuracy: 0.9000\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8750 - val_loss: 0.3642 - val_accuracy: 0.9100\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8825 - val_loss: 0.3618 - val_accuracy: 0.9000\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8800 - val_loss: 0.3585 - val_accuracy: 0.9100\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8925 - val_loss: 0.3554 - val_accuracy: 0.9100\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8800 - val_loss: 0.3533 - val_accuracy: 0.9000\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8950 - val_loss: 0.3497 - val_accuracy: 0.9100\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8850 - val_loss: 0.3466 - val_accuracy: 0.9000\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8825 - val_loss: 0.3444 - val_accuracy: 0.9000\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8900 - val_loss: 0.3412 - val_accuracy: 0.9000\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8825 - val_loss: 0.3392 - val_accuracy: 0.9000\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8925 - val_loss: 0.3365 - val_accuracy: 0.9000\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8900 - val_loss: 0.3347 - val_accuracy: 0.9000\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3249 - accuracy: 0.8925 - val_loss: 0.3332 - val_accuracy: 0.9000\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.8925 - val_loss: 0.3316 - val_accuracy: 0.9000\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8825 - val_loss: 0.3299 - val_accuracy: 0.8900\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8975 - val_loss: 0.3284 - val_accuracy: 0.8900\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.8950 - val_loss: 0.3258 - val_accuracy: 0.9000\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8825 - val_loss: 0.3235 - val_accuracy: 0.8900\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.9025 - val_loss: 0.3219 - val_accuracy: 0.8900\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8900 - val_loss: 0.3205 - val_accuracy: 0.8900\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.9000 - val_loss: 0.3190 - val_accuracy: 0.9000\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8900 - val_loss: 0.3169 - val_accuracy: 0.8900\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.9025 - val_loss: 0.3154 - val_accuracy: 0.9000\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8950 - val_loss: 0.3159 - val_accuracy: 0.8700\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.9000 - val_loss: 0.3144 - val_accuracy: 0.8900\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3012 - accuracy: 0.8950 - val_loss: 0.3106 - val_accuracy: 0.8800\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.9000 - val_loss: 0.3092 - val_accuracy: 0.8900\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.8925 - val_loss: 0.3125 - val_accuracy: 0.8700\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8900 - val_loss: 0.3075 - val_accuracy: 0.8900\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8950 - val_loss: 0.3054 - val_accuracy: 0.8800\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 0.9100 - val_loss: 0.3050 - val_accuracy: 0.8900\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.8900 - val_loss: 0.3023 - val_accuracy: 0.8900\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.9050 - val_loss: 0.3010 - val_accuracy: 0.8800\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8925 - val_loss: 0.3028 - val_accuracy: 0.8900\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.9000 - val_loss: 0.3035 - val_accuracy: 0.8700\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.9025 - val_loss: 0.3008 - val_accuracy: 0.8900\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.8950 - val_loss: 0.3004 - val_accuracy: 0.8700\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.8950 - val_loss: 0.2984 - val_accuracy: 0.8900\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.9025 - val_loss: 0.2967 - val_accuracy: 0.8800\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.8925 - val_loss: 0.2970 - val_accuracy: 0.8700\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.9100 - val_loss: 0.2952 - val_accuracy: 0.8900\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.8900 - val_loss: 0.2960 - val_accuracy: 0.8700\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.9000 - val_loss: 0.2980 - val_accuracy: 0.8700\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.9050 - val_loss: 0.2930 - val_accuracy: 0.8900\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2713 - accuracy: 0.9000 - val_loss: 0.2926 - val_accuracy: 0.8700\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.9050 - val_loss: 0.2904 - val_accuracy: 0.8800\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.8900 - val_loss: 0.2890 - val_accuracy: 0.8900\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.9025 - val_loss: 0.2922 - val_accuracy: 0.8700\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2691 - accuracy: 0.9025 - val_loss: 0.2922 - val_accuracy: 0.8800\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.9000 - val_loss: 0.2934 - val_accuracy: 0.8800\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.9000 - val_loss: 0.2900 - val_accuracy: 0.8700\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.9000 - val_loss: 0.2891 - val_accuracy: 0.8700\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.9075 - val_loss: 0.2879 - val_accuracy: 0.8700\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2680 - accuracy: 0.8950 - val_loss: 0.2861 - val_accuracy: 0.8800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5UpaNlYo1kS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_losses(hist):\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'])\n",
        "    plt.show()\n",
        "def plot_accuracies(hist):\n",
        "    plt.plot(hist.history['accuracy'])\n",
        "    plt.plot(hist.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'])\n",
        "    plt.show()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXZkpQLoo8EH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "bdd8b901-0e33-4913-9006-855b8e940cf4"
      },
      "source": [
        "# plot your losses and accuracies\n",
        "plot_losses(hist)\n",
        "plot_accuracies(hist)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww-Md7typd-Y",
        "colab_type": "text"
      },
      "source": [
        "###iii.a) How did the model perform.\n",
        "How did your neural network preform? What hyperparameters and optimizer did you choose? Was the model able to outperform Logistic Regression? Outperform Binary Sign Classification? If it did, why do you think your neural network beat these other models? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_er49nZQ8KZT",
        "colab_type": "text"
      },
      "source": [
        "The model performed well with an accuracy of around 87%. The optimizer was already chosen for us (Adam). I chose a combination of tanh and sigmoid with the number of neurons indicated in the instructions. Binary Cross Entropy was used for loss. I kept the number of ephochs the same as well as the validation split. The model was able to outperform the Logistic Regression. This was because the model was able to use a combination of sigmoid and tanh instead of just one line. The model was not able to outperform the binary sign classification. This is because I was able to adjust most of the parameters of the binary sign classification model. Had I been able to adjust the neural network parameters, I probably would have had a higher accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg0cuChfqAeN",
        "colab_type": "text"
      },
      "source": [
        "#2) Neural Network Classification\n",
        "Next, we move on to using an artificial Neural Network for a task that is a bit harder. We will see if we can train our model to determine if patients with suffering from heart disease died during follow up treatment. The dataset has 299 samples with 12 features each and a target class:\n",
        "<ul>\n",
        "<li>age: age of the patient (years)</li>\n",
        "<li>anaemia: decrease of red blood cells or hemoglobin (boolean)</li>\n",
        "<li>high blood pressure: if the patient has hypertension (boolean)</li>\n",
        "<li>creatinine phosphokinase (CPK): level of the CPK enzyme in the blood (mcg/L)</li>\n",
        "<li> diabetes: if the patient has diabetes (boolean)</li>\n",
        "<li> ejection fraction: percentage of blood leaving the heart at each contraction (percentage)</li>\n",
        "<li> platelets: platelets in the blood (kiloplatelets/mL)</li>\n",
        "<li> sex: woman or man (binary)</li>\n",
        "<li> serum creatinine: level of serum creatinine in the blood (mg/dL)</li>\n",
        "<li> serum sodium: level of serum sodium in the blood (mEq/L)</li>\n",
        "<li> smoking: if the patient smokes or not (boolean)</li>\n",
        "<li> time: follow-up period (days)</li>\n",
        "<li> [target] death event: if the patient deceased during the follow-up period (boolean)</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYCxTMRTqHVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c36ad914-97c9-44eb-fe5b-c3efee010bf4"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-12 21:43:26--  https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12239 (12K) [application/x-httpd-php]\n",
            "Saving to: ‘heart_failure_clinical_records_dataset.csv.72’\n",
            "\n",
            "\r          heart_fai   0%[                    ]       0  --.-KB/s               \rheart_failure_clini 100%[===================>]  11.95K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-12 21:43:26 (119 MB/s) - ‘heart_failure_clinical_records_dataset.csv.72’ saved [12239/12239]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jN9GUJc5efm",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAnMB4IdsmB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the data\n",
        "nn_dataframe = pd.read_csv('heart_failure_clinical_records_dataset.csv',sep=',')\n",
        "nn_dataframe.dropna(inplace=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beZmSQSGs7OY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b3b60121-7a67-49cb-90d8-3af28d951abc"
      },
      "source": [
        "# Check data\n",
        "nn_dataframe.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0  75.0        0                       582  ...        0     4            1\n",
              "1  55.0        0                      7861  ...        0     6            1\n",
              "2  65.0        0                       146  ...        1     7            1\n",
              "3  50.0        1                       111  ...        0     7            1\n",
              "4  65.0        1                       160  ...        0     8            1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tQzTnqM5iwa",
        "colab_type": "text"
      },
      "source": [
        "Split Data into X and y. Then scale the X data for model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii4SZM7V4sO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = nn_dataframe.iloc[:, 0:12]\n",
        "y = nn_dataframe.iloc[:,12]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-xQPQ0l6EdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8b66a8f8-1b3f-4279-f8cc-ec3e20d1d6f6"
      },
      "source": [
        "# Check X data\n",
        "X.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  ...  sex  smoking  time\n",
              "0  75.0        0                       582  ...    1        0     4\n",
              "1  55.0        0                      7861  ...    1        0     6\n",
              "2  65.0        0                       146  ...    1        1     7\n",
              "3  50.0        1                       111  ...    1        0     7\n",
              "4  65.0        1                       160  ...    0        0     8\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjlVsp8e9OYf",
        "colab_type": "text"
      },
      "source": [
        "###2.a) Use MinMaxScaler() to preprocess the dataset.\n",
        "This is similar to standardization but will transform all the feature values to between 0 and 1. \\\\\n",
        "**Hint: read information on MinMaxScaler (and other preprocessing transforms here):https://scikit-learn.org/stable/modules/preprocessing.html#normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONPM0qASs_RH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "X = X.values # Returns a numpy array\n",
        "# YOUR CODE HERE define the MinMaxScaler object\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# YOUR CODE HERE fit the MinMaxScaler\n",
        "X = min_max_scaler.fit_transform(X)\n",
        "\n",
        "# Create numpy array of labels\n",
        "y = y.values"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vq_1fsx8APo",
        "colab_type": "text"
      },
      "source": [
        "###2.b) Implement an Artificial Neural network\n",
        "Make a neural network to your liking. Define the input layer. Add Layers, specify the number of neurons in each layer, and the activation. and define the out layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPlsmcCj70Cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BUILD NETWORK HERE\n",
        "def build_model1():\n",
        "    input_layer = Input(shape=(12))\n",
        "    x = Dense(14, activation='tanh')(input_layer)\n",
        "    x = Dense(13, activation='tanh')(x)\n",
        "    x = Dense(4, activation='tanh')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    return Model(input_layer, x)\n",
        "\n",
        "model = build_model1()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNsNcghG8ar8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "52f7a95a-452a-4406-928c-034366afc535"
      },
      "source": [
        "# Show a summary of your model\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 12)]              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 14)                182       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 13)                195       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4)                 56        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 438\n",
            "Trainable params: 438\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKkah73t8e6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile your model with the chosen optimizer, binary cross entropy for the loss, and accuracy as the metric\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer,loss='bce',metrics=['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9VxLYDf8h-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d1db265-0423-4678-d243-4c51532c3c5b"
      },
      "source": [
        "# Call fit on your model passing in the X, y data above, train for 100 epochs\n",
        "hist = model.fit(X, y, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.7265 - accuracy: 0.4854 - val_loss: 0.7039 - val_accuracy: 0.4500\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.5272 - val_loss: 0.6033 - val_accuracy: 0.7000\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.5690 - val_loss: 0.5585 - val_accuracy: 0.9333\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6713 - accuracy: 0.6067 - val_loss: 0.5224 - val_accuracy: 0.9500\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6642 - accuracy: 0.6192 - val_loss: 0.4944 - val_accuracy: 0.9500\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6557 - accuracy: 0.6318 - val_loss: 0.4867 - val_accuracy: 0.9500\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6487 - accuracy: 0.6318 - val_loss: 0.4705 - val_accuracy: 0.9500\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6419 - accuracy: 0.6402 - val_loss: 0.4594 - val_accuracy: 0.9500\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6360 - accuracy: 0.6485 - val_loss: 0.4551 - val_accuracy: 0.9500\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6290 - accuracy: 0.6695 - val_loss: 0.4417 - val_accuracy: 0.9500\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.6653 - val_loss: 0.4243 - val_accuracy: 0.9500\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6158 - accuracy: 0.6778 - val_loss: 0.4089 - val_accuracy: 0.9500\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.6862 - val_loss: 0.3983 - val_accuracy: 0.9500\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6018 - accuracy: 0.6904 - val_loss: 0.3805 - val_accuracy: 0.9500\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5953 - accuracy: 0.6946 - val_loss: 0.3655 - val_accuracy: 0.9500\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6987 - val_loss: 0.3533 - val_accuracy: 0.9500\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5817 - accuracy: 0.7238 - val_loss: 0.3482 - val_accuracy: 0.9500\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.7280 - val_loss: 0.3369 - val_accuracy: 0.9500\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5667 - accuracy: 0.7364 - val_loss: 0.3207 - val_accuracy: 0.9500\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5591 - accuracy: 0.7531 - val_loss: 0.3060 - val_accuracy: 0.9500\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7531 - val_loss: 0.2962 - val_accuracy: 0.9500\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5443 - accuracy: 0.7573 - val_loss: 0.2833 - val_accuracy: 0.9500\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7615 - val_loss: 0.2759 - val_accuracy: 0.9500\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7531 - val_loss: 0.2684 - val_accuracy: 0.9500\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7573 - val_loss: 0.2643 - val_accuracy: 0.9500\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.7699 - val_loss: 0.2597 - val_accuracy: 0.9500\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.7782 - val_loss: 0.2511 - val_accuracy: 0.9500\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7657 - val_loss: 0.2440 - val_accuracy: 0.9500\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7741 - val_loss: 0.2399 - val_accuracy: 0.9500\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4958 - accuracy: 0.7741 - val_loss: 0.2357 - val_accuracy: 0.9500\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7824 - val_loss: 0.2296 - val_accuracy: 0.9500\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7824 - val_loss: 0.2250 - val_accuracy: 0.9500\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7782 - val_loss: 0.2243 - val_accuracy: 0.9500\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7824 - val_loss: 0.2224 - val_accuracy: 0.9500\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.8033 - val_loss: 0.2213 - val_accuracy: 0.9500\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.7908 - val_loss: 0.2176 - val_accuracy: 0.9500\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7908 - val_loss: 0.2158 - val_accuracy: 0.9500\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7908 - val_loss: 0.2146 - val_accuracy: 0.9500\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7992 - val_loss: 0.2137 - val_accuracy: 0.9500\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.8033 - val_loss: 0.2121 - val_accuracy: 0.9500\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7950 - val_loss: 0.2103 - val_accuracy: 0.9500\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8075 - val_loss: 0.2098 - val_accuracy: 0.9500\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.8117 - val_loss: 0.2085 - val_accuracy: 0.9500\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.8159 - val_loss: 0.2075 - val_accuracy: 0.9500\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.8117 - val_loss: 0.2067 - val_accuracy: 0.9500\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.8033 - val_loss: 0.2068 - val_accuracy: 0.9500\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8075 - val_loss: 0.2051 - val_accuracy: 0.9500\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8117 - val_loss: 0.2041 - val_accuracy: 0.9500\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.8117 - val_loss: 0.2033 - val_accuracy: 0.9500\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7950 - val_loss: 0.2034 - val_accuracy: 0.9500\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.8243 - val_loss: 0.2024 - val_accuracy: 0.9500\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.8075 - val_loss: 0.2015 - val_accuracy: 0.9500\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.8159 - val_loss: 0.2009 - val_accuracy: 0.9500\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.8159 - val_loss: 0.2003 - val_accuracy: 0.9500\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.8159 - val_loss: 0.1996 - val_accuracy: 0.9500\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8243 - val_loss: 0.1997 - val_accuracy: 0.9500\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8285 - val_loss: 0.1995 - val_accuracy: 0.9500\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.8285 - val_loss: 0.1993 - val_accuracy: 0.9500\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8326 - val_loss: 0.1989 - val_accuracy: 0.9500\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8285 - val_loss: 0.1983 - val_accuracy: 0.9500\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8201 - val_loss: 0.1980 - val_accuracy: 0.9500\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8368 - val_loss: 0.1975 - val_accuracy: 0.9500\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8285 - val_loss: 0.1972 - val_accuracy: 0.9500\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.8243 - val_loss: 0.1968 - val_accuracy: 0.9500\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8368 - val_loss: 0.1968 - val_accuracy: 0.9500\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.8201 - val_loss: 0.1966 - val_accuracy: 0.9500\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8201 - val_loss: 0.1961 - val_accuracy: 0.9500\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.8201 - val_loss: 0.1954 - val_accuracy: 0.9500\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.8285 - val_loss: 0.1952 - val_accuracy: 0.9500\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.8326 - val_loss: 0.1953 - val_accuracy: 0.9500\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8410 - val_loss: 0.1950 - val_accuracy: 0.9500\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8285 - val_loss: 0.1948 - val_accuracy: 0.9500\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8326 - val_loss: 0.1944 - val_accuracy: 0.9500\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.8285 - val_loss: 0.1946 - val_accuracy: 0.9500\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8368 - val_loss: 0.1941 - val_accuracy: 0.9500\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8368 - val_loss: 0.1940 - val_accuracy: 0.9500\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8410 - val_loss: 0.1935 - val_accuracy: 0.9500\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.8368 - val_loss: 0.1929 - val_accuracy: 0.9500\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8285 - val_loss: 0.1931 - val_accuracy: 0.9500\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8201 - val_loss: 0.1927 - val_accuracy: 0.9500\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8326 - val_loss: 0.1925 - val_accuracy: 0.9500\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8452 - val_loss: 0.1928 - val_accuracy: 0.9500\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8410 - val_loss: 0.1928 - val_accuracy: 0.9500\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8368 - val_loss: 0.1927 - val_accuracy: 0.9500\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8410 - val_loss: 0.1923 - val_accuracy: 0.9500\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8285 - val_loss: 0.1926 - val_accuracy: 0.9500\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8368 - val_loss: 0.1924 - val_accuracy: 0.9500\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8285 - val_loss: 0.1926 - val_accuracy: 0.9500\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8368 - val_loss: 0.1921 - val_accuracy: 0.9500\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8368 - val_loss: 0.1922 - val_accuracy: 0.9500\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8452 - val_loss: 0.1916 - val_accuracy: 0.9500\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8410 - val_loss: 0.1915 - val_accuracy: 0.9500\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8410 - val_loss: 0.1915 - val_accuracy: 0.9500\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8326 - val_loss: 0.1916 - val_accuracy: 0.9500\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.8368 - val_loss: 0.1910 - val_accuracy: 0.9500\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8452 - val_loss: 0.1910 - val_accuracy: 0.9500\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8410 - val_loss: 0.1912 - val_accuracy: 0.9500\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.8410 - val_loss: 0.1907 - val_accuracy: 0.9500\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8410 - val_loss: 0.1914 - val_accuracy: 0.9500\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8326 - val_loss: 0.1915 - val_accuracy: 0.9500\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8285 - val_loss: 0.1911 - val_accuracy: 0.9500\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8410 - val_loss: 0.1902 - val_accuracy: 0.9500\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8494 - val_loss: 0.1900 - val_accuracy: 0.9500\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8326 - val_loss: 0.1904 - val_accuracy: 0.9500\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8201 - val_loss: 0.1906 - val_accuracy: 0.9500\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8285 - val_loss: 0.1903 - val_accuracy: 0.9500\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8452 - val_loss: 0.1898 - val_accuracy: 0.9500\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8368 - val_loss: 0.1903 - val_accuracy: 0.9500\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8285 - val_loss: 0.1904 - val_accuracy: 0.9500\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8368 - val_loss: 0.1888 - val_accuracy: 0.9500\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8410 - val_loss: 0.1892 - val_accuracy: 0.9500\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8410 - val_loss: 0.1899 - val_accuracy: 0.9500\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8159 - val_loss: 0.1899 - val_accuracy: 0.9500\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8243 - val_loss: 0.1889 - val_accuracy: 0.9500\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8452 - val_loss: 0.1888 - val_accuracy: 0.9500\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8410 - val_loss: 0.1889 - val_accuracy: 0.9500\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8368 - val_loss: 0.1891 - val_accuracy: 0.9500\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8452 - val_loss: 0.1880 - val_accuracy: 0.9500\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8452 - val_loss: 0.1882 - val_accuracy: 0.9500\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8452 - val_loss: 0.1887 - val_accuracy: 0.9500\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8368 - val_loss: 0.1888 - val_accuracy: 0.9500\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8326 - val_loss: 0.1890 - val_accuracy: 0.9500\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8452 - val_loss: 0.1884 - val_accuracy: 0.9500\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8410 - val_loss: 0.1888 - val_accuracy: 0.9500\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8410 - val_loss: 0.1883 - val_accuracy: 0.9500\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8494 - val_loss: 0.1876 - val_accuracy: 0.9500\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8452 - val_loss: 0.1879 - val_accuracy: 0.9500\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8410 - val_loss: 0.1886 - val_accuracy: 0.9500\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8368 - val_loss: 0.1874 - val_accuracy: 0.9500\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8536 - val_loss: 0.1880 - val_accuracy: 0.9500\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8410 - val_loss: 0.1882 - val_accuracy: 0.9500\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8410 - val_loss: 0.1879 - val_accuracy: 0.9500\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8326 - val_loss: 0.1880 - val_accuracy: 0.9500\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8410 - val_loss: 0.1876 - val_accuracy: 0.9500\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8410 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8452 - val_loss: 0.1873 - val_accuracy: 0.9500\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8410 - val_loss: 0.1878 - val_accuracy: 0.9500\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8452 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.8494 - val_loss: 0.1862 - val_accuracy: 0.9500\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8452 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8494 - val_loss: 0.1861 - val_accuracy: 0.9500\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8452 - val_loss: 0.1860 - val_accuracy: 0.9500\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8452 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8285 - val_loss: 0.1865 - val_accuracy: 0.9500\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8536 - val_loss: 0.1859 - val_accuracy: 0.9500\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8494 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8285 - val_loss: 0.1873 - val_accuracy: 0.9500\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8326 - val_loss: 0.1864 - val_accuracy: 0.9500\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8326 - val_loss: 0.1857 - val_accuracy: 0.9500\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8368 - val_loss: 0.1855 - val_accuracy: 0.9500\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8452 - val_loss: 0.1840 - val_accuracy: 0.9500\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8536 - val_loss: 0.1850 - val_accuracy: 0.9500\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8368 - val_loss: 0.1863 - val_accuracy: 0.9500\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8410 - val_loss: 0.1846 - val_accuracy: 0.9500\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8494 - val_loss: 0.1850 - val_accuracy: 0.9500\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8452 - val_loss: 0.1858 - val_accuracy: 0.9500\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8494 - val_loss: 0.1845 - val_accuracy: 0.9500\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8494 - val_loss: 0.1849 - val_accuracy: 0.9500\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8410 - val_loss: 0.1842 - val_accuracy: 0.9500\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8494 - val_loss: 0.1838 - val_accuracy: 0.9500\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8452 - val_loss: 0.1832 - val_accuracy: 0.9500\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8285 - val_loss: 0.1826 - val_accuracy: 0.9500\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8243 - val_loss: 0.1829 - val_accuracy: 0.9500\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8494 - val_loss: 0.1816 - val_accuracy: 0.9500\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8452 - val_loss: 0.1832 - val_accuracy: 0.9500\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8452 - val_loss: 0.1825 - val_accuracy: 0.9500\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8410 - val_loss: 0.1830 - val_accuracy: 0.9500\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8452 - val_loss: 0.1820 - val_accuracy: 0.9500\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8494 - val_loss: 0.1820 - val_accuracy: 0.9500\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8452 - val_loss: 0.1834 - val_accuracy: 0.9500\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8368 - val_loss: 0.1826 - val_accuracy: 0.9500\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8452 - val_loss: 0.1823 - val_accuracy: 0.9500\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8368 - val_loss: 0.1815 - val_accuracy: 0.9500\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3997 - accuracy: 0.8494 - val_loss: 0.1803 - val_accuracy: 0.9500\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8410 - val_loss: 0.1823 - val_accuracy: 0.9500\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8368 - val_loss: 0.1813 - val_accuracy: 0.9500\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8452 - val_loss: 0.1813 - val_accuracy: 0.9500\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8452 - val_loss: 0.1818 - val_accuracy: 0.9500\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8452 - val_loss: 0.1818 - val_accuracy: 0.9500\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8452 - val_loss: 0.1803 - val_accuracy: 0.9500\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8452 - val_loss: 0.1816 - val_accuracy: 0.9500\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8410 - val_loss: 0.1814 - val_accuracy: 0.9500\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8368 - val_loss: 0.1792 - val_accuracy: 0.9500\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8494 - val_loss: 0.1803 - val_accuracy: 0.9500\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8452 - val_loss: 0.1803 - val_accuracy: 0.9500\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8452 - val_loss: 0.1788 - val_accuracy: 0.9500\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8452 - val_loss: 0.1790 - val_accuracy: 0.9500\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8452 - val_loss: 0.1799 - val_accuracy: 0.9500\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3923 - accuracy: 0.8410 - val_loss: 0.1797 - val_accuracy: 0.9500\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8494 - val_loss: 0.1778 - val_accuracy: 0.9500\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8452 - val_loss: 0.1779 - val_accuracy: 0.9500\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8410 - val_loss: 0.1783 - val_accuracy: 0.9500\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8452 - val_loss: 0.1773 - val_accuracy: 0.9500\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8410 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8410 - val_loss: 0.1767 - val_accuracy: 0.9500\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8494 - val_loss: 0.1762 - val_accuracy: 0.9500\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8494 - val_loss: 0.1771 - val_accuracy: 0.9500\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8536 - val_loss: 0.1754 - val_accuracy: 0.9500\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8536 - val_loss: 0.1775 - val_accuracy: 0.9500\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8410 - val_loss: 0.1761 - val_accuracy: 0.9500\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8536 - val_loss: 0.1751 - val_accuracy: 0.9500\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8368 - val_loss: 0.1761 - val_accuracy: 0.9500\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8494 - val_loss: 0.1743 - val_accuracy: 0.9500\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8577 - val_loss: 0.1731 - val_accuracy: 0.9500\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8536 - val_loss: 0.1752 - val_accuracy: 0.9500\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8452 - val_loss: 0.1748 - val_accuracy: 0.9500\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8410 - val_loss: 0.1745 - val_accuracy: 0.9500\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.8494 - val_loss: 0.1754 - val_accuracy: 0.9500\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8494 - val_loss: 0.1740 - val_accuracy: 0.9500\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8452 - val_loss: 0.1719 - val_accuracy: 0.9500\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8410 - val_loss: 0.1755 - val_accuracy: 0.9500\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8452 - val_loss: 0.1752 - val_accuracy: 0.9500\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8494 - val_loss: 0.1742 - val_accuracy: 0.9500\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8494 - val_loss: 0.1744 - val_accuracy: 0.9500\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8494 - val_loss: 0.1734 - val_accuracy: 0.9500\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8410 - val_loss: 0.1730 - val_accuracy: 0.9500\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8494 - val_loss: 0.1740 - val_accuracy: 0.9500\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8536 - val_loss: 0.1733 - val_accuracy: 0.9500\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8494 - val_loss: 0.1750 - val_accuracy: 0.9500\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8577 - val_loss: 0.1730 - val_accuracy: 0.9500\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8577 - val_loss: 0.1711 - val_accuracy: 0.9500\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8494 - val_loss: 0.1719 - val_accuracy: 0.9500\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8494 - val_loss: 0.1722 - val_accuracy: 0.9500\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8494 - val_loss: 0.1711 - val_accuracy: 0.9500\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8536 - val_loss: 0.1709 - val_accuracy: 0.9500\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8577 - val_loss: 0.1713 - val_accuracy: 0.9500\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8494 - val_loss: 0.1715 - val_accuracy: 0.9500\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8577 - val_loss: 0.1704 - val_accuracy: 0.9500\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8577 - val_loss: 0.1705 - val_accuracy: 0.9500\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8536 - val_loss: 0.1730 - val_accuracy: 0.9500\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8452 - val_loss: 0.1727 - val_accuracy: 0.9500\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8536 - val_loss: 0.1688 - val_accuracy: 0.9500\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8619 - val_loss: 0.1698 - val_accuracy: 0.9500\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8494 - val_loss: 0.1717 - val_accuracy: 0.9500\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8536 - val_loss: 0.1697 - val_accuracy: 0.9500\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8536 - val_loss: 0.1687 - val_accuracy: 0.9500\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8494 - val_loss: 0.1708 - val_accuracy: 0.9500\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8536 - val_loss: 0.1702 - val_accuracy: 0.9500\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8577 - val_loss: 0.1694 - val_accuracy: 0.9500\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8619 - val_loss: 0.1681 - val_accuracy: 0.9500\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8619 - val_loss: 0.1682 - val_accuracy: 0.9500\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8619 - val_loss: 0.1707 - val_accuracy: 0.9500\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8536 - val_loss: 0.1702 - val_accuracy: 0.9500\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8494 - val_loss: 0.1707 - val_accuracy: 0.9500\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8577 - val_loss: 0.1684 - val_accuracy: 0.9500\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8619 - val_loss: 0.1686 - val_accuracy: 0.9500\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8494 - val_loss: 0.1692 - val_accuracy: 0.9500\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8494 - val_loss: 0.1694 - val_accuracy: 0.9500\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8536 - val_loss: 0.1670 - val_accuracy: 0.9500\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8619 - val_loss: 0.1680 - val_accuracy: 0.9500\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8619 - val_loss: 0.1674 - val_accuracy: 0.9500\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8536 - val_loss: 0.1671 - val_accuracy: 0.9500\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8661 - val_loss: 0.1672 - val_accuracy: 0.9500\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8619 - val_loss: 0.1680 - val_accuracy: 0.9500\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8494 - val_loss: 0.1688 - val_accuracy: 0.9500\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8452 - val_loss: 0.1682 - val_accuracy: 0.9500\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8703 - val_loss: 0.1665 - val_accuracy: 0.9500\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8703 - val_loss: 0.1670 - val_accuracy: 0.9500\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8452 - val_loss: 0.1685 - val_accuracy: 0.9500\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8494 - val_loss: 0.1667 - val_accuracy: 0.9500\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8619 - val_loss: 0.1655 - val_accuracy: 0.9500\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8577 - val_loss: 0.1661 - val_accuracy: 0.9500\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8494 - val_loss: 0.1676 - val_accuracy: 0.9500\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8452 - val_loss: 0.1670 - val_accuracy: 0.9500\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8452 - val_loss: 0.1669 - val_accuracy: 0.9500\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3684 - accuracy: 0.8536 - val_loss: 0.1658 - val_accuracy: 0.9500\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8619 - val_loss: 0.1662 - val_accuracy: 0.9500\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8577 - val_loss: 0.1662 - val_accuracy: 0.9500\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8577 - val_loss: 0.1661 - val_accuracy: 0.9500\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8619 - val_loss: 0.1662 - val_accuracy: 0.9500\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8536 - val_loss: 0.1664 - val_accuracy: 0.9500\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8494 - val_loss: 0.1654 - val_accuracy: 0.9500\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8577 - val_loss: 0.1657 - val_accuracy: 0.9500\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8619 - val_loss: 0.1652 - val_accuracy: 0.9500\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8661 - val_loss: 0.1658 - val_accuracy: 0.9500\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8619 - val_loss: 0.1649 - val_accuracy: 0.9500\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8619 - val_loss: 0.1663 - val_accuracy: 0.9500\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8536 - val_loss: 0.1665 - val_accuracy: 0.9500\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8536 - val_loss: 0.1652 - val_accuracy: 0.9500\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8661 - val_loss: 0.1651 - val_accuracy: 0.9500\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8619 - val_loss: 0.1660 - val_accuracy: 0.9500\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8577 - val_loss: 0.1657 - val_accuracy: 0.9500\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8494 - val_loss: 0.1657 - val_accuracy: 0.9500\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8577 - val_loss: 0.1639 - val_accuracy: 0.9500\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8577 - val_loss: 0.1643 - val_accuracy: 0.9500\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8536 - val_loss: 0.1648 - val_accuracy: 0.9500\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8619 - val_loss: 0.1634 - val_accuracy: 0.9500\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3619 - accuracy: 0.8577 - val_loss: 0.1638 - val_accuracy: 0.9500\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8619 - val_loss: 0.1636 - val_accuracy: 0.9500\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.8661 - val_loss: 0.1633 - val_accuracy: 0.9500\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8577 - val_loss: 0.1652 - val_accuracy: 0.9500\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3616 - accuracy: 0.8536 - val_loss: 0.1647 - val_accuracy: 0.9500\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8577 - val_loss: 0.1642 - val_accuracy: 0.9500\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8661 - val_loss: 0.1633 - val_accuracy: 0.9500\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8619 - val_loss: 0.1635 - val_accuracy: 0.9500\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8619 - val_loss: 0.1639 - val_accuracy: 0.9500\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8536 - val_loss: 0.1640 - val_accuracy: 0.9500\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8536 - val_loss: 0.1627 - val_accuracy: 0.9500\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3593 - accuracy: 0.8703 - val_loss: 0.1625 - val_accuracy: 0.9500\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8536 - val_loss: 0.1638 - val_accuracy: 0.9500\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8494 - val_loss: 0.1635 - val_accuracy: 0.9500\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8619 - val_loss: 0.1630 - val_accuracy: 0.9500\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8619 - val_loss: 0.1633 - val_accuracy: 0.9500\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.8577 - val_loss: 0.1637 - val_accuracy: 0.9500\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8577 - val_loss: 0.1636 - val_accuracy: 0.9500\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3557 - accuracy: 0.8661 - val_loss: 0.1621 - val_accuracy: 0.9500\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8703 - val_loss: 0.1616 - val_accuracy: 0.9500\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8619 - val_loss: 0.1628 - val_accuracy: 0.9500\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8619 - val_loss: 0.1621 - val_accuracy: 0.9500\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8661 - val_loss: 0.1617 - val_accuracy: 0.9500\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8577 - val_loss: 0.1627 - val_accuracy: 0.9500\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8577 - val_loss: 0.1629 - val_accuracy: 0.9500\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8577 - val_loss: 0.1609 - val_accuracy: 0.9500\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8577 - val_loss: 0.1618 - val_accuracy: 0.9500\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8577 - val_loss: 0.1619 - val_accuracy: 0.9500\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8494 - val_loss: 0.1622 - val_accuracy: 0.9500\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8619 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8661 - val_loss: 0.1611 - val_accuracy: 0.9500\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8661 - val_loss: 0.1615 - val_accuracy: 0.9500\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3534 - accuracy: 0.8619 - val_loss: 0.1615 - val_accuracy: 0.9500\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.8703 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8703 - val_loss: 0.1617 - val_accuracy: 0.9500\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3524 - accuracy: 0.8619 - val_loss: 0.1615 - val_accuracy: 0.9500\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8619 - val_loss: 0.1619 - val_accuracy: 0.9500\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8619 - val_loss: 0.1614 - val_accuracy: 0.9500\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3513 - accuracy: 0.8619 - val_loss: 0.1617 - val_accuracy: 0.9500\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3527 - accuracy: 0.8577 - val_loss: 0.1620 - val_accuracy: 0.9500\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8619 - val_loss: 0.1609 - val_accuracy: 0.9500\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8577 - val_loss: 0.1612 - val_accuracy: 0.9500\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3524 - accuracy: 0.8619 - val_loss: 0.1609 - val_accuracy: 0.9500\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8661 - val_loss: 0.1619 - val_accuracy: 0.9500\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.8661 - val_loss: 0.1614 - val_accuracy: 0.9500\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.8703 - val_loss: 0.1608 - val_accuracy: 0.9500\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8703 - val_loss: 0.1607 - val_accuracy: 0.9500\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8661 - val_loss: 0.1610 - val_accuracy: 0.9500\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8661 - val_loss: 0.1596 - val_accuracy: 0.9500\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8661 - val_loss: 0.1596 - val_accuracy: 0.9500\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8703 - val_loss: 0.1607 - val_accuracy: 0.9500\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3487 - accuracy: 0.8577 - val_loss: 0.1600 - val_accuracy: 0.9500\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8619 - val_loss: 0.1605 - val_accuracy: 0.9500\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.8619 - val_loss: 0.1605 - val_accuracy: 0.9500\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3481 - accuracy: 0.8661 - val_loss: 0.1603 - val_accuracy: 0.9500\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.8745 - val_loss: 0.1601 - val_accuracy: 0.9500\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3468 - accuracy: 0.8703 - val_loss: 0.1604 - val_accuracy: 0.9500\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.8661 - val_loss: 0.1602 - val_accuracy: 0.9500\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3473 - accuracy: 0.8745 - val_loss: 0.1595 - val_accuracy: 0.9500\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3507 - accuracy: 0.8745 - val_loss: 0.1594 - val_accuracy: 0.9500\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8661 - val_loss: 0.1605 - val_accuracy: 0.9500\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.8703 - val_loss: 0.1592 - val_accuracy: 0.9500\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3468 - accuracy: 0.8661 - val_loss: 0.1594 - val_accuracy: 0.9500\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8745 - val_loss: 0.1591 - val_accuracy: 0.9500\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3466 - accuracy: 0.8703 - val_loss: 0.1591 - val_accuracy: 0.9500\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3446 - accuracy: 0.8745 - val_loss: 0.1588 - val_accuracy: 0.9500\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8661 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8703 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8745 - val_loss: 0.1590 - val_accuracy: 0.9500\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8745 - val_loss: 0.1586 - val_accuracy: 0.9500\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3437 - accuracy: 0.8703 - val_loss: 0.1589 - val_accuracy: 0.9500\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8703 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3439 - accuracy: 0.8619 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.8661 - val_loss: 0.1592 - val_accuracy: 0.9500\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3423 - accuracy: 0.8703 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3434 - accuracy: 0.8703 - val_loss: 0.1583 - val_accuracy: 0.9500\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8661 - val_loss: 0.1586 - val_accuracy: 0.9500\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8661 - val_loss: 0.1596 - val_accuracy: 0.9500\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8661 - val_loss: 0.1586 - val_accuracy: 0.9500\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8703 - val_loss: 0.1578 - val_accuracy: 0.9500\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8745 - val_loss: 0.1583 - val_accuracy: 0.9500\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3403 - accuracy: 0.8870 - val_loss: 0.1596 - val_accuracy: 0.9500\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8661 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8703 - val_loss: 0.1576 - val_accuracy: 0.9500\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.8661 - val_loss: 0.1582 - val_accuracy: 0.9500\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8661 - val_loss: 0.1582 - val_accuracy: 0.9500\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8745 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8703 - val_loss: 0.1593 - val_accuracy: 0.9500\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3431 - accuracy: 0.8577 - val_loss: 0.1574 - val_accuracy: 0.9500\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8745 - val_loss: 0.1578 - val_accuracy: 0.9500\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3386 - accuracy: 0.8745 - val_loss: 0.1587 - val_accuracy: 0.9500\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8661 - val_loss: 0.1586 - val_accuracy: 0.9500\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3388 - accuracy: 0.8745 - val_loss: 0.1580 - val_accuracy: 0.9500\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.8787 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8745 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.8745 - val_loss: 0.1581 - val_accuracy: 0.9500\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8745 - val_loss: 0.1579 - val_accuracy: 0.9500\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8703 - val_loss: 0.1574 - val_accuracy: 0.9500\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8661 - val_loss: 0.1573 - val_accuracy: 0.9500\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3378 - accuracy: 0.8661 - val_loss: 0.1577 - val_accuracy: 0.9500\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3368 - accuracy: 0.8661 - val_loss: 0.1575 - val_accuracy: 0.9500\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8661 - val_loss: 0.1581 - val_accuracy: 0.9500\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8703 - val_loss: 0.1576 - val_accuracy: 0.9500\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3357 - accuracy: 0.8745 - val_loss: 0.1575 - val_accuracy: 0.9500\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8703 - val_loss: 0.1571 - val_accuracy: 0.9500\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8703 - val_loss: 0.1574 - val_accuracy: 0.9500\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8703 - val_loss: 0.1576 - val_accuracy: 0.9500\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8619 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.8661 - val_loss: 0.1572 - val_accuracy: 0.9500\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8661 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8661 - val_loss: 0.1571 - val_accuracy: 0.9500\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8745 - val_loss: 0.1573 - val_accuracy: 0.9500\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8703 - val_loss: 0.1575 - val_accuracy: 0.9500\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8661 - val_loss: 0.1579 - val_accuracy: 0.9500\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8577 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8661 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8703 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8703 - val_loss: 0.1566 - val_accuracy: 0.9500\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8745 - val_loss: 0.1573 - val_accuracy: 0.9500\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8703 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8745 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3303 - accuracy: 0.8787 - val_loss: 0.1567 - val_accuracy: 0.9500\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8703 - val_loss: 0.1578 - val_accuracy: 0.9500\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8703 - val_loss: 0.1579 - val_accuracy: 0.9500\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8787 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8745 - val_loss: 0.1578 - val_accuracy: 0.9500\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8745 - val_loss: 0.1579 - val_accuracy: 0.9500\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8619 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8703 - val_loss: 0.1573 - val_accuracy: 0.9500\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8661 - val_loss: 0.1577 - val_accuracy: 0.9500\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8661 - val_loss: 0.1565 - val_accuracy: 0.9500\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8745 - val_loss: 0.1561 - val_accuracy: 0.9500\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8745 - val_loss: 0.1560 - val_accuracy: 0.9500\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8745 - val_loss: 0.1563 - val_accuracy: 0.9500\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8703 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8745 - val_loss: 0.1564 - val_accuracy: 0.9500\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8745 - val_loss: 0.1562 - val_accuracy: 0.9500\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8828 - val_loss: 0.1567 - val_accuracy: 0.9500\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3269 - accuracy: 0.8745 - val_loss: 0.1565 - val_accuracy: 0.9500\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8745 - val_loss: 0.1563 - val_accuracy: 0.9500\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3257 - accuracy: 0.8703 - val_loss: 0.1563 - val_accuracy: 0.9500\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8703 - val_loss: 0.1566 - val_accuracy: 0.9500\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3248 - accuracy: 0.8703 - val_loss: 0.1562 - val_accuracy: 0.9500\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8703 - val_loss: 0.1561 - val_accuracy: 0.9500\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8661 - val_loss: 0.1560 - val_accuracy: 0.9500\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8661 - val_loss: 0.1565 - val_accuracy: 0.9500\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3247 - accuracy: 0.8703 - val_loss: 0.1559 - val_accuracy: 0.9500\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8745 - val_loss: 0.1558 - val_accuracy: 0.9500\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8703 - val_loss: 0.1555 - val_accuracy: 0.9500\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3240 - accuracy: 0.8703 - val_loss: 0.1564 - val_accuracy: 0.9500\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3240 - accuracy: 0.8703 - val_loss: 0.1556 - val_accuracy: 0.9500\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.8703 - val_loss: 0.1557 - val_accuracy: 0.9500\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3223 - accuracy: 0.8703 - val_loss: 0.1557 - val_accuracy: 0.9500\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.8703 - val_loss: 0.1557 - val_accuracy: 0.9500\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8703 - val_loss: 0.1552 - val_accuracy: 0.9500\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3224 - accuracy: 0.8703 - val_loss: 0.1551 - val_accuracy: 0.9500\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3224 - accuracy: 0.8703 - val_loss: 0.1555 - val_accuracy: 0.9500\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3216 - accuracy: 0.8703 - val_loss: 0.1554 - val_accuracy: 0.9500\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8661 - val_loss: 0.1553 - val_accuracy: 0.9500\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.8745 - val_loss: 0.1555 - val_accuracy: 0.9500\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3215 - accuracy: 0.8703 - val_loss: 0.1554 - val_accuracy: 0.9500\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3215 - accuracy: 0.8661 - val_loss: 0.1552 - val_accuracy: 0.9500\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.8619 - val_loss: 0.1550 - val_accuracy: 0.9500\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.1549 - val_accuracy: 0.9500\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.8745 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3198 - accuracy: 0.8745 - val_loss: 0.1542 - val_accuracy: 0.9500\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3191 - accuracy: 0.8787 - val_loss: 0.1542 - val_accuracy: 0.9500\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8828 - val_loss: 0.1550 - val_accuracy: 0.9500\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.8745 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3183 - accuracy: 0.8619 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3175 - accuracy: 0.8661 - val_loss: 0.1550 - val_accuracy: 0.9500\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3178 - accuracy: 0.8661 - val_loss: 0.1548 - val_accuracy: 0.9500\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3172 - accuracy: 0.8661 - val_loss: 0.1548 - val_accuracy: 0.9500\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3206 - accuracy: 0.8661 - val_loss: 0.1551 - val_accuracy: 0.9500\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3172 - accuracy: 0.8745 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8703 - val_loss: 0.1545 - val_accuracy: 0.9500\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8828 - val_loss: 0.1542 - val_accuracy: 0.9500\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8661 - val_loss: 0.1550 - val_accuracy: 0.9500\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8619 - val_loss: 0.1550 - val_accuracy: 0.9500\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3147 - accuracy: 0.8619 - val_loss: 0.1549 - val_accuracy: 0.9500\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3166 - accuracy: 0.8619 - val_loss: 0.1547 - val_accuracy: 0.9500\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3173 - accuracy: 0.8703 - val_loss: 0.1544 - val_accuracy: 0.9500\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.8577 - val_loss: 0.1544 - val_accuracy: 0.9500\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8661 - val_loss: 0.1539 - val_accuracy: 0.9500\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8703 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3144 - accuracy: 0.8787 - val_loss: 0.1533 - val_accuracy: 0.9500\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8745 - val_loss: 0.1531 - val_accuracy: 0.9500\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3133 - accuracy: 0.8703 - val_loss: 0.1537 - val_accuracy: 0.9500\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3148 - accuracy: 0.8703 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3158 - accuracy: 0.8745 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3135 - accuracy: 0.8661 - val_loss: 0.1537 - val_accuracy: 0.9500\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3172 - accuracy: 0.8703 - val_loss: 0.1537 - val_accuracy: 0.9500\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3125 - accuracy: 0.8787 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.8661 - val_loss: 0.1532 - val_accuracy: 0.9500\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3102 - accuracy: 0.8703 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3105 - accuracy: 0.8745 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8661 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3110 - accuracy: 0.8661 - val_loss: 0.1529 - val_accuracy: 0.9500\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3115 - accuracy: 0.8661 - val_loss: 0.1526 - val_accuracy: 0.9500\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3091 - accuracy: 0.8619 - val_loss: 0.1525 - val_accuracy: 0.9500\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8745 - val_loss: 0.1524 - val_accuracy: 0.9500\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8745 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8661 - val_loss: 0.1522 - val_accuracy: 0.9500\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8745 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.8703 - val_loss: 0.1515 - val_accuracy: 0.9500\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8703 - val_loss: 0.1515 - val_accuracy: 0.9500\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3091 - accuracy: 0.8703 - val_loss: 0.1519 - val_accuracy: 0.9500\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3088 - accuracy: 0.8703 - val_loss: 0.1514 - val_accuracy: 0.9500\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3076 - accuracy: 0.8661 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3067 - accuracy: 0.8661 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3064 - accuracy: 0.8703 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3069 - accuracy: 0.8661 - val_loss: 0.1514 - val_accuracy: 0.9500\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3055 - accuracy: 0.8661 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.8661 - val_loss: 0.1516 - val_accuracy: 0.9500\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8787 - val_loss: 0.1519 - val_accuracy: 0.9500\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3077 - accuracy: 0.8703 - val_loss: 0.1515 - val_accuracy: 0.9500\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3057 - accuracy: 0.8703 - val_loss: 0.1512 - val_accuracy: 0.9500\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3045 - accuracy: 0.8703 - val_loss: 0.1513 - val_accuracy: 0.9500\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.8661 - val_loss: 0.1513 - val_accuracy: 0.9500\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3049 - accuracy: 0.8745 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3039 - accuracy: 0.8703 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8703 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8828 - val_loss: 0.1502 - val_accuracy: 0.9500\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8787 - val_loss: 0.1501 - val_accuracy: 0.9500\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8703 - val_loss: 0.1519 - val_accuracy: 0.9500\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8828 - val_loss: 0.1519 - val_accuracy: 0.9500\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3102 - accuracy: 0.8787 - val_loss: 0.1511 - val_accuracy: 0.9500\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3053 - accuracy: 0.8745 - val_loss: 0.1513 - val_accuracy: 0.9500\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3030 - accuracy: 0.8703 - val_loss: 0.1508 - val_accuracy: 0.9500\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8828 - val_loss: 0.1504 - val_accuracy: 0.9500\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3013 - accuracy: 0.8703 - val_loss: 0.1497 - val_accuracy: 0.9500\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8745 - val_loss: 0.1498 - val_accuracy: 0.9500\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3016 - accuracy: 0.8828 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3019 - accuracy: 0.8828 - val_loss: 0.1501 - val_accuracy: 0.9500\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8745 - val_loss: 0.1500 - val_accuracy: 0.9500\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3011 - accuracy: 0.8828 - val_loss: 0.1501 - val_accuracy: 0.9500\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3007 - accuracy: 0.8745 - val_loss: 0.1511 - val_accuracy: 0.9500\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2997 - accuracy: 0.8787 - val_loss: 0.1508 - val_accuracy: 0.9500\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3000 - accuracy: 0.8703 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2987 - accuracy: 0.8745 - val_loss: 0.1502 - val_accuracy: 0.9500\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8787 - val_loss: 0.1503 - val_accuracy: 0.9500\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2974 - accuracy: 0.8828 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8828 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2997 - accuracy: 0.8828 - val_loss: 0.1500 - val_accuracy: 0.9500\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.8745 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2981 - accuracy: 0.8828 - val_loss: 0.1497 - val_accuracy: 0.9500\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2973 - accuracy: 0.8828 - val_loss: 0.1497 - val_accuracy: 0.9500\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2967 - accuracy: 0.8787 - val_loss: 0.1504 - val_accuracy: 0.9500\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8745 - val_loss: 0.1499 - val_accuracy: 0.9500\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8828 - val_loss: 0.1499 - val_accuracy: 0.9500\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2970 - accuracy: 0.8787 - val_loss: 0.1512 - val_accuracy: 0.9500\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2990 - accuracy: 0.8787 - val_loss: 0.1507 - val_accuracy: 0.9500\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2962 - accuracy: 0.8828 - val_loss: 0.1504 - val_accuracy: 0.9500\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2982 - accuracy: 0.8870 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3052 - accuracy: 0.8703 - val_loss: 0.1493 - val_accuracy: 0.9500\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.8828 - val_loss: 0.1503 - val_accuracy: 0.9500\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2987 - accuracy: 0.8954 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.8870 - val_loss: 0.1491 - val_accuracy: 0.9500\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2952 - accuracy: 0.8828 - val_loss: 0.1500 - val_accuracy: 0.9500\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2937 - accuracy: 0.8828 - val_loss: 0.1499 - val_accuracy: 0.9500\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.8828 - val_loss: 0.1496 - val_accuracy: 0.9500\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2932 - accuracy: 0.8828 - val_loss: 0.1496 - val_accuracy: 0.9500\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.8828 - val_loss: 0.1490 - val_accuracy: 0.9500\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2925 - accuracy: 0.8828 - val_loss: 0.1493 - val_accuracy: 0.9500\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2925 - accuracy: 0.8870 - val_loss: 0.1489 - val_accuracy: 0.9500\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2934 - accuracy: 0.8787 - val_loss: 0.1487 - val_accuracy: 0.9500\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.8912 - val_loss: 0.1493 - val_accuracy: 0.9500\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8912 - val_loss: 0.1484 - val_accuracy: 0.9500\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8912 - val_loss: 0.1486 - val_accuracy: 0.9500\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2928 - accuracy: 0.8954 - val_loss: 0.1498 - val_accuracy: 0.9500\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2903 - accuracy: 0.8996 - val_loss: 0.1488 - val_accuracy: 0.9500\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2935 - accuracy: 0.8912 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.8787 - val_loss: 0.1485 - val_accuracy: 0.9500\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2905 - accuracy: 0.8828 - val_loss: 0.1496 - val_accuracy: 0.9500\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2957 - accuracy: 0.8912 - val_loss: 0.1493 - val_accuracy: 0.9500\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2897 - accuracy: 0.8870 - val_loss: 0.1480 - val_accuracy: 0.9500\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2934 - accuracy: 0.8912 - val_loss: 0.1476 - val_accuracy: 0.9500\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2880 - accuracy: 0.8828 - val_loss: 0.1486 - val_accuracy: 0.9500\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2918 - accuracy: 0.8912 - val_loss: 0.1510 - val_accuracy: 0.9500\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2896 - accuracy: 0.8870 - val_loss: 0.1498 - val_accuracy: 0.9500\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.8870 - val_loss: 0.1487 - val_accuracy: 0.9500\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2880 - accuracy: 0.8870 - val_loss: 0.1485 - val_accuracy: 0.9500\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8954 - val_loss: 0.1486 - val_accuracy: 0.9500\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.8870 - val_loss: 0.1473 - val_accuracy: 0.9500\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2860 - accuracy: 0.8912 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2940 - accuracy: 0.8954 - val_loss: 0.1483 - val_accuracy: 0.9500\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.8870 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2910 - accuracy: 0.8870 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2917 - accuracy: 0.8954 - val_loss: 0.1494 - val_accuracy: 0.9500\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2891 - accuracy: 0.8954 - val_loss: 0.1482 - val_accuracy: 0.9500\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2899 - accuracy: 0.8870 - val_loss: 0.1477 - val_accuracy: 0.9500\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.8870 - val_loss: 0.1495 - val_accuracy: 0.9500\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2864 - accuracy: 0.8912 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2865 - accuracy: 0.8870 - val_loss: 0.1478 - val_accuracy: 0.9500\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2864 - accuracy: 0.8828 - val_loss: 0.1484 - val_accuracy: 0.9500\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2867 - accuracy: 0.8912 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2850 - accuracy: 0.8870 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.8828 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.8912 - val_loss: 0.1475 - val_accuracy: 0.9500\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2851 - accuracy: 0.8996 - val_loss: 0.1475 - val_accuracy: 0.9500\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2846 - accuracy: 0.8912 - val_loss: 0.1465 - val_accuracy: 0.9500\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2857 - accuracy: 0.8828 - val_loss: 0.1477 - val_accuracy: 0.9500\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2858 - accuracy: 0.8870 - val_loss: 0.1495 - val_accuracy: 0.9500\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2849 - accuracy: 0.8870 - val_loss: 0.1475 - val_accuracy: 0.9500\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2834 - accuracy: 0.8870 - val_loss: 0.1471 - val_accuracy: 0.9500\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2823 - accuracy: 0.8954 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2829 - accuracy: 0.9079 - val_loss: 0.1461 - val_accuracy: 0.9500\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2826 - accuracy: 0.8954 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2846 - accuracy: 0.8870 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2836 - accuracy: 0.8912 - val_loss: 0.1477 - val_accuracy: 0.9500\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2832 - accuracy: 0.8912 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2823 - accuracy: 0.8954 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2822 - accuracy: 0.8996 - val_loss: 0.1468 - val_accuracy: 0.9500\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2824 - accuracy: 0.8912 - val_loss: 0.1480 - val_accuracy: 0.9500\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2812 - accuracy: 0.8912 - val_loss: 0.1466 - val_accuracy: 0.9500\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2826 - accuracy: 0.8870 - val_loss: 0.1465 - val_accuracy: 0.9500\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2821 - accuracy: 0.8996 - val_loss: 0.1482 - val_accuracy: 0.9500\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2822 - accuracy: 0.8996 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2831 - accuracy: 0.8912 - val_loss: 0.1463 - val_accuracy: 0.9500\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2824 - accuracy: 0.8912 - val_loss: 0.1450 - val_accuracy: 0.9500\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8996 - val_loss: 0.1473 - val_accuracy: 0.9500\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.9079 - val_loss: 0.1463 - val_accuracy: 0.9500\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2794 - accuracy: 0.8954 - val_loss: 0.1468 - val_accuracy: 0.9500\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2782 - accuracy: 0.8954 - val_loss: 0.1474 - val_accuracy: 0.9500\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.9079 - val_loss: 0.1474 - val_accuracy: 0.9500\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2805 - accuracy: 0.9079 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2785 - accuracy: 0.8954 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2818 - accuracy: 0.8996 - val_loss: 0.1466 - val_accuracy: 0.9500\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2812 - accuracy: 0.9121 - val_loss: 0.1452 - val_accuracy: 0.9500\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2775 - accuracy: 0.8996 - val_loss: 0.1459 - val_accuracy: 0.9500\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.8954 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.9079 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2767 - accuracy: 0.9038 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2760 - accuracy: 0.8954 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.8870 - val_loss: 0.1462 - val_accuracy: 0.9500\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2751 - accuracy: 0.9079 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2781 - accuracy: 0.9079 - val_loss: 0.1473 - val_accuracy: 0.9500\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2760 - accuracy: 0.8996 - val_loss: 0.1459 - val_accuracy: 0.9500\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2758 - accuracy: 0.8954 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.9079 - val_loss: 0.1479 - val_accuracy: 0.9500\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2753 - accuracy: 0.9121 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2766 - accuracy: 0.8912 - val_loss: 0.1455 - val_accuracy: 0.9500\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2742 - accuracy: 0.8954 - val_loss: 0.1459 - val_accuracy: 0.9500\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.9121 - val_loss: 0.1462 - val_accuracy: 0.9500\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.9121 - val_loss: 0.1455 - val_accuracy: 0.9500\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.8954 - val_loss: 0.1450 - val_accuracy: 0.9500\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.8996 - val_loss: 0.1450 - val_accuracy: 0.9500\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.8954 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2758 - accuracy: 0.8996 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8996 - val_loss: 0.1447 - val_accuracy: 0.9500\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2732 - accuracy: 0.9038 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.8996 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2736 - accuracy: 0.8912 - val_loss: 0.1450 - val_accuracy: 0.9500\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2720 - accuracy: 0.9079 - val_loss: 0.1465 - val_accuracy: 0.9500\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2728 - accuracy: 0.9079 - val_loss: 0.1462 - val_accuracy: 0.9500\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2723 - accuracy: 0.9038 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2733 - accuracy: 0.8954 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2725 - accuracy: 0.8954 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2717 - accuracy: 0.9038 - val_loss: 0.1455 - val_accuracy: 0.9500\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2709 - accuracy: 0.9038 - val_loss: 0.1456 - val_accuracy: 0.9500\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2719 - accuracy: 0.8996 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2723 - accuracy: 0.8996 - val_loss: 0.1468 - val_accuracy: 0.9500\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.9038 - val_loss: 0.1456 - val_accuracy: 0.9500\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2706 - accuracy: 0.9038 - val_loss: 0.1446 - val_accuracy: 0.9500\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2699 - accuracy: 0.9038 - val_loss: 0.1455 - val_accuracy: 0.9500\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2705 - accuracy: 0.8954 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2716 - accuracy: 0.8954 - val_loss: 0.1456 - val_accuracy: 0.9500\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.8996 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2696 - accuracy: 0.9038 - val_loss: 0.1447 - val_accuracy: 0.9500\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2693 - accuracy: 0.9038 - val_loss: 0.1455 - val_accuracy: 0.9500\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2690 - accuracy: 0.8996 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2698 - accuracy: 0.9038 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.9038 - val_loss: 0.1447 - val_accuracy: 0.9500\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.8954 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2683 - accuracy: 0.8996 - val_loss: 0.1437 - val_accuracy: 0.9500\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.9079 - val_loss: 0.1446 - val_accuracy: 0.9500\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2683 - accuracy: 0.9121 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2702 - accuracy: 0.9038 - val_loss: 0.1439 - val_accuracy: 0.9500\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2667 - accuracy: 0.8996 - val_loss: 0.1445 - val_accuracy: 0.9500\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2694 - accuracy: 0.9079 - val_loss: 0.1431 - val_accuracy: 0.9500\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2675 - accuracy: 0.9121 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2665 - accuracy: 0.9079 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2674 - accuracy: 0.8996 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.8996 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2666 - accuracy: 0.8954 - val_loss: 0.1440 - val_accuracy: 0.9500\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.8954 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2661 - accuracy: 0.9079 - val_loss: 0.1456 - val_accuracy: 0.9500\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2667 - accuracy: 0.9079 - val_loss: 0.1452 - val_accuracy: 0.9500\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2670 - accuracy: 0.9079 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2666 - accuracy: 0.9038 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2705 - accuracy: 0.8996 - val_loss: 0.1433 - val_accuracy: 0.9500\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2655 - accuracy: 0.9038 - val_loss: 0.1458 - val_accuracy: 0.9500\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2688 - accuracy: 0.9079 - val_loss: 0.1452 - val_accuracy: 0.9500\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2639 - accuracy: 0.9038 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2675 - accuracy: 0.8996 - val_loss: 0.1460 - val_accuracy: 0.9500\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2640 - accuracy: 0.8954 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2644 - accuracy: 0.8996 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2640 - accuracy: 0.9121 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2639 - accuracy: 0.9121 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2658 - accuracy: 0.9079 - val_loss: 0.1436 - val_accuracy: 0.9500\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2670 - accuracy: 0.9121 - val_loss: 0.1435 - val_accuracy: 0.9500\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2650 - accuracy: 0.9079 - val_loss: 0.1424 - val_accuracy: 0.9500\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.9038 - val_loss: 0.1436 - val_accuracy: 0.9500\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2631 - accuracy: 0.9079 - val_loss: 0.1433 - val_accuracy: 0.9500\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2644 - accuracy: 0.8996 - val_loss: 0.1437 - val_accuracy: 0.9500\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2624 - accuracy: 0.9038 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2639 - accuracy: 0.9038 - val_loss: 0.1427 - val_accuracy: 0.9500\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2638 - accuracy: 0.9079 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2638 - accuracy: 0.9079 - val_loss: 0.1414 - val_accuracy: 0.9500\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2625 - accuracy: 0.9038 - val_loss: 0.1421 - val_accuracy: 0.9500\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2619 - accuracy: 0.9038 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2620 - accuracy: 0.9038 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2618 - accuracy: 0.9038 - val_loss: 0.1431 - val_accuracy: 0.9500\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2630 - accuracy: 0.9038 - val_loss: 0.1440 - val_accuracy: 0.9500\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2613 - accuracy: 0.8996 - val_loss: 0.1436 - val_accuracy: 0.9500\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2625 - accuracy: 0.9163 - val_loss: 0.1435 - val_accuracy: 0.9500\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2612 - accuracy: 0.9079 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2610 - accuracy: 0.9038 - val_loss: 0.1435 - val_accuracy: 0.9500\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9079 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2624 - accuracy: 0.8996 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2626 - accuracy: 0.9038 - val_loss: 0.1421 - val_accuracy: 0.9500\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2587 - accuracy: 0.9079 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2613 - accuracy: 0.9121 - val_loss: 0.1434 - val_accuracy: 0.9500\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.9121 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2628 - accuracy: 0.9038 - val_loss: 0.1427 - val_accuracy: 0.9500\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2588 - accuracy: 0.9079 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2603 - accuracy: 0.8996 - val_loss: 0.1431 - val_accuracy: 0.9500\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2584 - accuracy: 0.9038 - val_loss: 0.1436 - val_accuracy: 0.9500\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.9038 - val_loss: 0.1447 - val_accuracy: 0.9500\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2588 - accuracy: 0.9079 - val_loss: 0.1437 - val_accuracy: 0.9500\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2624 - accuracy: 0.9079 - val_loss: 0.1441 - val_accuracy: 0.9500\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2587 - accuracy: 0.9079 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2603 - accuracy: 0.8996 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2588 - accuracy: 0.9121 - val_loss: 0.1439 - val_accuracy: 0.9500\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2595 - accuracy: 0.9163 - val_loss: 0.1421 - val_accuracy: 0.9500\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2581 - accuracy: 0.9038 - val_loss: 0.1415 - val_accuracy: 0.9500\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.9038 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2613 - accuracy: 0.8996 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2581 - accuracy: 0.9121 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2584 - accuracy: 0.8954 - val_loss: 0.1424 - val_accuracy: 0.9500\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2563 - accuracy: 0.9121 - val_loss: 0.1433 - val_accuracy: 0.9500\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.9079 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.9038 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2556 - accuracy: 0.9079 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2563 - accuracy: 0.9079 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.9121 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2574 - accuracy: 0.9079 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2591 - accuracy: 0.9205 - val_loss: 0.1450 - val_accuracy: 0.9500\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2555 - accuracy: 0.9079 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2567 - accuracy: 0.9038 - val_loss: 0.1441 - val_accuracy: 0.9500\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2567 - accuracy: 0.8996 - val_loss: 0.1429 - val_accuracy: 0.9500\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2538 - accuracy: 0.9079 - val_loss: 0.1426 - val_accuracy: 0.9500\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2563 - accuracy: 0.9163 - val_loss: 0.1431 - val_accuracy: 0.9500\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2530 - accuracy: 0.9079 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2555 - accuracy: 0.9038 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2573 - accuracy: 0.9121 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2549 - accuracy: 0.9079 - val_loss: 0.1414 - val_accuracy: 0.9500\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2572 - accuracy: 0.8996 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.9038 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.9079 - val_loss: 0.1429 - val_accuracy: 0.9500\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2529 - accuracy: 0.9079 - val_loss: 0.1429 - val_accuracy: 0.9500\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2577 - accuracy: 0.9121 - val_loss: 0.1431 - val_accuracy: 0.9500\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.8996 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.8954 - val_loss: 0.1426 - val_accuracy: 0.9500\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2555 - accuracy: 0.9079 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2566 - accuracy: 0.8996 - val_loss: 0.1413 - val_accuracy: 0.9500\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2527 - accuracy: 0.9038 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2525 - accuracy: 0.9163 - val_loss: 0.1427 - val_accuracy: 0.9500\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.9163 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2525 - accuracy: 0.9038 - val_loss: 0.1421 - val_accuracy: 0.9500\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2515 - accuracy: 0.9038 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2515 - accuracy: 0.9121 - val_loss: 0.1427 - val_accuracy: 0.9500\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2541 - accuracy: 0.8954 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2518 - accuracy: 0.9079 - val_loss: 0.1431 - val_accuracy: 0.9500\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9163 - val_loss: 0.1436 - val_accuracy: 0.9500\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.9121 - val_loss: 0.1424 - val_accuracy: 0.9500\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2512 - accuracy: 0.9038 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2514 - accuracy: 0.9163 - val_loss: 0.1446 - val_accuracy: 0.9500\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9163 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.9163 - val_loss: 0.1433 - val_accuracy: 0.9500\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2499 - accuracy: 0.9121 - val_loss: 0.1437 - val_accuracy: 0.9500\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.9121 - val_loss: 0.1434 - val_accuracy: 0.9500\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2511 - accuracy: 0.9163 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.9079 - val_loss: 0.1407 - val_accuracy: 0.9500\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2513 - accuracy: 0.9079 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.9121 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2507 - accuracy: 0.9163 - val_loss: 0.1428 - val_accuracy: 0.9500\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.9163 - val_loss: 0.1429 - val_accuracy: 0.9500\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2484 - accuracy: 0.9121 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.9121 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2484 - accuracy: 0.9121 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2475 - accuracy: 0.9121 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.8996 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2465 - accuracy: 0.9205 - val_loss: 0.1437 - val_accuracy: 0.9500\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2484 - accuracy: 0.9163 - val_loss: 0.1427 - val_accuracy: 0.9500\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2466 - accuracy: 0.9079 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2500 - accuracy: 0.9038 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.9205 - val_loss: 0.1438 - val_accuracy: 0.9500\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2489 - accuracy: 0.9163 - val_loss: 0.1409 - val_accuracy: 0.9500\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2461 - accuracy: 0.9247 - val_loss: 0.1396 - val_accuracy: 0.9500\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2472 - accuracy: 0.9163 - val_loss: 0.1395 - val_accuracy: 0.9500\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2464 - accuracy: 0.9079 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2465 - accuracy: 0.9079 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2465 - accuracy: 0.9163 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.9205 - val_loss: 0.1415 - val_accuracy: 0.9500\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2466 - accuracy: 0.9079 - val_loss: 0.1398 - val_accuracy: 0.9500\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2453 - accuracy: 0.9163 - val_loss: 0.1415 - val_accuracy: 0.9500\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2464 - accuracy: 0.9163 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.9205 - val_loss: 0.1402 - val_accuracy: 0.9500\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2466 - accuracy: 0.9163 - val_loss: 0.1394 - val_accuracy: 0.9500\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2451 - accuracy: 0.9205 - val_loss: 0.1404 - val_accuracy: 0.9500\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2469 - accuracy: 0.9121 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2433 - accuracy: 0.9247 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2476 - accuracy: 0.9038 - val_loss: 0.1409 - val_accuracy: 0.9500\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2462 - accuracy: 0.9079 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2459 - accuracy: 0.9163 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2439 - accuracy: 0.9205 - val_loss: 0.1414 - val_accuracy: 0.9500\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2446 - accuracy: 0.9247 - val_loss: 0.1414 - val_accuracy: 0.9500\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2450 - accuracy: 0.9205 - val_loss: 0.1416 - val_accuracy: 0.9500\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2446 - accuracy: 0.9079 - val_loss: 0.1407 - val_accuracy: 0.9500\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2442 - accuracy: 0.9079 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2436 - accuracy: 0.9205 - val_loss: 0.1431 - val_accuracy: 0.9500\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2448 - accuracy: 0.9163 - val_loss: 0.1414 - val_accuracy: 0.9500\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2418 - accuracy: 0.9205 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2451 - accuracy: 0.9079 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2505 - accuracy: 0.9163 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2481 - accuracy: 0.9079 - val_loss: 0.1404 - val_accuracy: 0.9500\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2477 - accuracy: 0.9121 - val_loss: 0.1410 - val_accuracy: 0.9500\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2435 - accuracy: 0.9205 - val_loss: 0.1390 - val_accuracy: 0.9500\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2426 - accuracy: 0.9163 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2425 - accuracy: 0.9121 - val_loss: 0.1401 - val_accuracy: 0.9500\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2420 - accuracy: 0.9205 - val_loss: 0.1410 - val_accuracy: 0.9500\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.9121 - val_loss: 0.1403 - val_accuracy: 0.9500\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.9163 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2422 - accuracy: 0.9205 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2427 - accuracy: 0.9079 - val_loss: 0.1403 - val_accuracy: 0.9500\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 0.9247 - val_loss: 0.1403 - val_accuracy: 0.9500\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2424 - accuracy: 0.9205 - val_loss: 0.1400 - val_accuracy: 0.9500\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2405 - accuracy: 0.9205 - val_loss: 0.1395 - val_accuracy: 0.9500\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2409 - accuracy: 0.9121 - val_loss: 0.1400 - val_accuracy: 0.9500\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2428 - accuracy: 0.9038 - val_loss: 0.1404 - val_accuracy: 0.9500\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2412 - accuracy: 0.9247 - val_loss: 0.1413 - val_accuracy: 0.9500\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.9079 - val_loss: 0.1400 - val_accuracy: 0.9500\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2446 - accuracy: 0.9247 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2406 - accuracy: 0.9247 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.9079 - val_loss: 0.1399 - val_accuracy: 0.9500\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2395 - accuracy: 0.9121 - val_loss: 0.1428 - val_accuracy: 0.9500\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.9163 - val_loss: 0.1416 - val_accuracy: 0.9500\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9247 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2404 - accuracy: 0.9079 - val_loss: 0.1409 - val_accuracy: 0.9500\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2405 - accuracy: 0.9247 - val_loss: 0.1398 - val_accuracy: 0.9500\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2383 - accuracy: 0.9247 - val_loss: 0.1397 - val_accuracy: 0.9500\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2391 - accuracy: 0.9247 - val_loss: 0.1400 - val_accuracy: 0.9500\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2413 - accuracy: 0.9205 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2397 - accuracy: 0.9289 - val_loss: 0.1426 - val_accuracy: 0.9500\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2401 - accuracy: 0.9205 - val_loss: 0.1394 - val_accuracy: 0.9500\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2381 - accuracy: 0.9247 - val_loss: 0.1392 - val_accuracy: 0.9500\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2379 - accuracy: 0.9247 - val_loss: 0.1395 - val_accuracy: 0.9500\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2375 - accuracy: 0.9289 - val_loss: 0.1401 - val_accuracy: 0.9500\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2375 - accuracy: 0.9163 - val_loss: 0.1397 - val_accuracy: 0.9500\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2379 - accuracy: 0.9163 - val_loss: 0.1398 - val_accuracy: 0.9500\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2380 - accuracy: 0.9205 - val_loss: 0.1400 - val_accuracy: 0.9500\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2394 - accuracy: 0.9163 - val_loss: 0.1395 - val_accuracy: 0.9500\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2371 - accuracy: 0.9163 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2375 - accuracy: 0.9205 - val_loss: 0.1409 - val_accuracy: 0.9500\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9205 - val_loss: 0.1402 - val_accuracy: 0.9500\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2377 - accuracy: 0.9121 - val_loss: 0.1407 - val_accuracy: 0.9500\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2358 - accuracy: 0.9247 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2364 - accuracy: 0.9247 - val_loss: 0.1416 - val_accuracy: 0.9500\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.9205 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2349 - accuracy: 0.9247 - val_loss: 0.1401 - val_accuracy: 0.9500\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2364 - accuracy: 0.9247 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2366 - accuracy: 0.9205 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2348 - accuracy: 0.9205 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2357 - accuracy: 0.9205 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2365 - accuracy: 0.9163 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2370 - accuracy: 0.9163 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.9205 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2364 - accuracy: 0.9121 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.9205 - val_loss: 0.1396 - val_accuracy: 0.9500\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2344 - accuracy: 0.9205 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2346 - accuracy: 0.9163 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2346 - accuracy: 0.9205 - val_loss: 0.1395 - val_accuracy: 0.9500\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2363 - accuracy: 0.9205 - val_loss: 0.1377 - val_accuracy: 0.9500\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2345 - accuracy: 0.9163 - val_loss: 0.1390 - val_accuracy: 0.9500\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2350 - accuracy: 0.9247 - val_loss: 0.1397 - val_accuracy: 0.9500\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2341 - accuracy: 0.9163 - val_loss: 0.1402 - val_accuracy: 0.9500\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2333 - accuracy: 0.9247 - val_loss: 0.1390 - val_accuracy: 0.9500\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.9247 - val_loss: 0.1376 - val_accuracy: 0.9500\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2341 - accuracy: 0.9289 - val_loss: 0.1402 - val_accuracy: 0.9500\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2335 - accuracy: 0.9247 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.9205 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9289 - val_loss: 0.1380 - val_accuracy: 0.9500\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2337 - accuracy: 0.9205 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.9247 - val_loss: 0.1413 - val_accuracy: 0.9500\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2322 - accuracy: 0.9289 - val_loss: 0.1409 - val_accuracy: 0.9500\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2325 - accuracy: 0.9331 - val_loss: 0.1401 - val_accuracy: 0.9500\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2337 - accuracy: 0.9289 - val_loss: 0.1393 - val_accuracy: 0.9500\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.9205 - val_loss: 0.1409 - val_accuracy: 0.9667\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.9247 - val_loss: 0.1407 - val_accuracy: 0.9500\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2312 - accuracy: 0.9289 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2318 - accuracy: 0.9289 - val_loss: 0.1413 - val_accuracy: 0.9500\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2319 - accuracy: 0.9205 - val_loss: 0.1416 - val_accuracy: 0.9500\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2341 - accuracy: 0.9205 - val_loss: 0.1414 - val_accuracy: 0.9500\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2345 - accuracy: 0.9205 - val_loss: 0.1413 - val_accuracy: 0.9667\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2313 - accuracy: 0.9247 - val_loss: 0.1386 - val_accuracy: 0.9500\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2340 - accuracy: 0.9163 - val_loss: 0.1394 - val_accuracy: 0.9500\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2302 - accuracy: 0.9247 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2311 - accuracy: 0.9289 - val_loss: 0.1385 - val_accuracy: 0.9500\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2295 - accuracy: 0.9289 - val_loss: 0.1412 - val_accuracy: 0.9500\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2312 - accuracy: 0.9331 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2301 - accuracy: 0.9289 - val_loss: 0.1400 - val_accuracy: 0.9500\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.9205 - val_loss: 0.1391 - val_accuracy: 0.9667\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2295 - accuracy: 0.9289 - val_loss: 0.1390 - val_accuracy: 0.9500\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2304 - accuracy: 0.9289 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2302 - accuracy: 0.9331 - val_loss: 0.1410 - val_accuracy: 0.9500\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2309 - accuracy: 0.9247 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2288 - accuracy: 0.9247 - val_loss: 0.1435 - val_accuracy: 0.9500\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.9205 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2297 - accuracy: 0.9205 - val_loss: 0.1387 - val_accuracy: 0.9500\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2299 - accuracy: 0.9289 - val_loss: 0.1410 - val_accuracy: 0.9667\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2288 - accuracy: 0.9205 - val_loss: 0.1404 - val_accuracy: 0.9667\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2294 - accuracy: 0.9247 - val_loss: 0.1393 - val_accuracy: 0.9500\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2285 - accuracy: 0.9205 - val_loss: 0.1404 - val_accuracy: 0.9500\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2286 - accuracy: 0.9205 - val_loss: 0.1396 - val_accuracy: 0.9500\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2289 - accuracy: 0.9247 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9205 - val_loss: 0.1401 - val_accuracy: 0.9667\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9247 - val_loss: 0.1399 - val_accuracy: 0.9667\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2292 - accuracy: 0.9247 - val_loss: 0.1385 - val_accuracy: 0.9500\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2275 - accuracy: 0.9289 - val_loss: 0.1388 - val_accuracy: 0.9500\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2275 - accuracy: 0.9247 - val_loss: 0.1389 - val_accuracy: 0.9667\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2272 - accuracy: 0.9289 - val_loss: 0.1385 - val_accuracy: 0.9500\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9331 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2267 - accuracy: 0.9331 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2281 - accuracy: 0.9247 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2276 - accuracy: 0.9331 - val_loss: 0.1388 - val_accuracy: 0.9500\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.9331 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2281 - accuracy: 0.9289 - val_loss: 0.1384 - val_accuracy: 0.9500\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2272 - accuracy: 0.9289 - val_loss: 0.1403 - val_accuracy: 0.9500\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2282 - accuracy: 0.9205 - val_loss: 0.1394 - val_accuracy: 0.9500\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2269 - accuracy: 0.9205 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2263 - accuracy: 0.9289 - val_loss: 0.1412 - val_accuracy: 0.9667\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2264 - accuracy: 0.9247 - val_loss: 0.1398 - val_accuracy: 0.9500\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2251 - accuracy: 0.9289 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2256 - accuracy: 0.9205 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9331 - val_loss: 0.1411 - val_accuracy: 0.9667\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2262 - accuracy: 0.9331 - val_loss: 0.1403 - val_accuracy: 0.9500\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2256 - accuracy: 0.9289 - val_loss: 0.1396 - val_accuracy: 0.9500\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9331 - val_loss: 0.1401 - val_accuracy: 0.9667\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 0.9205 - val_loss: 0.1408 - val_accuracy: 0.9667\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2261 - accuracy: 0.9247 - val_loss: 0.1404 - val_accuracy: 0.9667\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2239 - accuracy: 0.9247 - val_loss: 0.1382 - val_accuracy: 0.9500\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2247 - accuracy: 0.9247 - val_loss: 0.1383 - val_accuracy: 0.9667\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2241 - accuracy: 0.9331 - val_loss: 0.1392 - val_accuracy: 0.9667\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2250 - accuracy: 0.9247 - val_loss: 0.1387 - val_accuracy: 0.9500\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2244 - accuracy: 0.9331 - val_loss: 0.1379 - val_accuracy: 0.9500\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2234 - accuracy: 0.9289 - val_loss: 0.1377 - val_accuracy: 0.9500\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2243 - accuracy: 0.9289 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2243 - accuracy: 0.9247 - val_loss: 0.1388 - val_accuracy: 0.9500\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2263 - accuracy: 0.9289 - val_loss: 0.1383 - val_accuracy: 0.9667\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2234 - accuracy: 0.9331 - val_loss: 0.1377 - val_accuracy: 0.9500\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2243 - accuracy: 0.9372 - val_loss: 0.1391 - val_accuracy: 0.9667\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2227 - accuracy: 0.9331 - val_loss: 0.1382 - val_accuracy: 0.9667\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9289 - val_loss: 0.1393 - val_accuracy: 0.9500\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2256 - accuracy: 0.9247 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2228 - accuracy: 0.9331 - val_loss: 0.1391 - val_accuracy: 0.9500\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2244 - accuracy: 0.9247 - val_loss: 0.1396 - val_accuracy: 0.9500\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.9163 - val_loss: 0.1401 - val_accuracy: 0.9500\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2260 - accuracy: 0.9205 - val_loss: 0.1421 - val_accuracy: 0.9667\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9205 - val_loss: 0.1401 - val_accuracy: 0.9500\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2263 - accuracy: 0.9205 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2228 - accuracy: 0.9205 - val_loss: 0.1421 - val_accuracy: 0.9667\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2232 - accuracy: 0.9331 - val_loss: 0.1417 - val_accuracy: 0.9667\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2237 - accuracy: 0.9205 - val_loss: 0.1410 - val_accuracy: 0.9500\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2220 - accuracy: 0.9289 - val_loss: 0.1395 - val_accuracy: 0.9667\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2235 - accuracy: 0.9247 - val_loss: 0.1398 - val_accuracy: 0.9667\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2229 - accuracy: 0.9289 - val_loss: 0.1395 - val_accuracy: 0.9500\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.9289 - val_loss: 0.1405 - val_accuracy: 0.9667\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2216 - accuracy: 0.9331 - val_loss: 0.1399 - val_accuracy: 0.9667\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9205 - val_loss: 0.1400 - val_accuracy: 0.9500\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9205 - val_loss: 0.1400 - val_accuracy: 0.9667\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2238 - accuracy: 0.9331 - val_loss: 0.1403 - val_accuracy: 0.9667\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2199 - accuracy: 0.9331 - val_loss: 0.1396 - val_accuracy: 0.9500\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2236 - accuracy: 0.9205 - val_loss: 0.1391 - val_accuracy: 0.9500\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2197 - accuracy: 0.9331 - val_loss: 0.1377 - val_accuracy: 0.9667\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2207 - accuracy: 0.9331 - val_loss: 0.1375 - val_accuracy: 0.9667\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2215 - accuracy: 0.9247 - val_loss: 0.1401 - val_accuracy: 0.9500\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2208 - accuracy: 0.9331 - val_loss: 0.1405 - val_accuracy: 0.9667\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2200 - accuracy: 0.9289 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2209 - accuracy: 0.9247 - val_loss: 0.1407 - val_accuracy: 0.9500\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2223 - accuracy: 0.9247 - val_loss: 0.1396 - val_accuracy: 0.9667\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2208 - accuracy: 0.9205 - val_loss: 0.1392 - val_accuracy: 0.9500\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2207 - accuracy: 0.9205 - val_loss: 0.1418 - val_accuracy: 0.9667\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2197 - accuracy: 0.9247 - val_loss: 0.1409 - val_accuracy: 0.9667\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2193 - accuracy: 0.9205 - val_loss: 0.1402 - val_accuracy: 0.9500\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.9289 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2194 - accuracy: 0.9247 - val_loss: 0.1398 - val_accuracy: 0.9667\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2216 - accuracy: 0.9205 - val_loss: 0.1376 - val_accuracy: 0.9500\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2196 - accuracy: 0.9331 - val_loss: 0.1381 - val_accuracy: 0.9667\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2200 - accuracy: 0.9289 - val_loss: 0.1383 - val_accuracy: 0.9667\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2176 - accuracy: 0.9289 - val_loss: 0.1376 - val_accuracy: 0.9667\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9289 - val_loss: 0.1378 - val_accuracy: 0.9667\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2182 - accuracy: 0.9289 - val_loss: 0.1381 - val_accuracy: 0.9667\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2182 - accuracy: 0.9289 - val_loss: 0.1383 - val_accuracy: 0.9667\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9247 - val_loss: 0.1379 - val_accuracy: 0.9667\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2181 - accuracy: 0.9372 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2237 - accuracy: 0.9247 - val_loss: 0.1376 - val_accuracy: 0.9667\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.2217 - accuracy: 0.9247 - val_loss: 0.1384 - val_accuracy: 0.9500\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2210 - accuracy: 0.9289 - val_loss: 0.1409 - val_accuracy: 0.9667\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2180 - accuracy: 0.9289 - val_loss: 0.1397 - val_accuracy: 0.9667\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9247 - val_loss: 0.1391 - val_accuracy: 0.9667\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9205 - val_loss: 0.1397 - val_accuracy: 0.9667\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2177 - accuracy: 0.9289 - val_loss: 0.1392 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gfI0hDAF99HJ"
      },
      "source": [
        "###2.c) How did the model perform.\n",
        "How did your neural network preform? What hyperparameters and optimizer did you choose? What activation did you use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kCtOgL-h99HL"
      },
      "source": [
        "The neural network performed well with an accurancy in the low to mid 90's. (After changing the epoch). I used the same optimizer as before, Adam. The loss was again set to a binary cross entropy and the validation split set to 0.2. This time however I changed the number of epochs in order to get a more accurate accuracy. Alternetively I probably could have adjusted the learning rate. A combination of tanh and sigmoid were also used. The number of neurons for each are based on a decreasing scale but more accuretly based on trial and error. Lots and lots of trial and error.\n",
        "\n"
      ]
    }
  ]
}